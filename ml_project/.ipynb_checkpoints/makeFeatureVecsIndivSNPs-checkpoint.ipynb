{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "fileDir  = \"/media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/\"\n",
    "outDir   = \"/media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A\"\n",
    "cmd      = 'ls ' + fileDir + '*ScanResults_with_sk-allel.txt'\n",
    "\n",
    "fileList =  subprocess.run(cmd, shell = True, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "fileList = fileList.split(\"\\n\")\n",
    "fileList = list(filter(None, fileList))\n",
    "\n",
    "if (len(fileList) == 0):\n",
    "    print(\"No files found when using command: \" + cmd)\n",
    "\n",
    "stats = [\"Hscan_v1.3_H12\", \"pcadapt_3.0.4_ALL_log10p\", \"OutFLANK_0.2_He\", \"LFMM_ridge_0.0_ALL_log10p\",\n",
    "        \"LFMM_lasso_0.0_ALL_log10p\", \"rehh_2.0.2_ALL_log10p\", \"Spearmans_ALL_rho\", \"a_freq_final\", \n",
    "        \"pcadapt_3.0.4_PRUNED_log10p\", \"RDAvegan_v2.5.2_ALL_loading_RDA1_envi\", \"LEA_1.2.0_ALL_K3_log10p\",\n",
    "         \"LEA_1.2.0_ALL_K3_z\", \"baypass_2.1_PRUNED_BF_env\", \"baypass_2.1_PRUNED_XTX\", \"OutFLANK_0.2_PRUNED_log10p\",\n",
    "        \"tajD_sk-allel_v1.1.10\", \"pi_sk-allel_v1.1.10\", \"thetaW_sk-allel_v1.1.10\", \"H12_sk-allel_v1.1.10\", \n",
    "        \"H2/H1_sk-allel_v1.1.10\", \"ihs_sk-allel_v1.1.10\",\"nsl_sk-allel_v1.1.10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats and Explanations\n",
    "\n",
    "**Hscan_v1.3_H12 :** identifies **selective sweeps** by detecting shifts in haplotype frequencies\n",
    "\n",
    "**pcadapt_3.0.4_ALL_log10p :** identifies **QTNs** by differentiation outlier analysis, detects outliers along principal components, effected by low recombination\n",
    "\n",
    "**OutFLANK_0.2_He :** the heterozygosity of the loci\n",
    "\n",
    "**LFMM_ridge_0.0_ALL_log10p :** GWAS method, detects loci that have effects on phenotypes (**QTNs**)\n",
    "\n",
    "**LFMM_lasso_0.0_ALL_log10p :** GWAS method that ids **QTNs**, shows signals in region of low RC more than ridge\n",
    "\n",
    "**rehh_2.0.2_ALL_log10p :** identifes recent, hard **selective sweeps** through reduction in haplotype diversity\n",
    "\n",
    "**Spearmans_ALL_rho :** GEA method that detects **QTNs**, does not correct for population structure\n",
    "\n",
    "**a_freq_final :** Frequency of the allele\n",
    "\n",
    "**pcadapt_3.0.4_PRUNED_log10p :** identifies **QTNs**, should be less effected by low recombination than pcadapt all\n",
    "\n",
    "**RDAvegan_v2.5.2_ALL_loading_RDA1_envi :** GEA method that detects **QTNs** and does not correct for population structure\n",
    "\n",
    "**LEA_1.2.0_ALL_K3_log10p :** GEA method to detect **QTNs**, corrects for population structure (pvalue)\n",
    "\n",
    "**LEA_1.2.0_ALL_K3_z :** GEA method to detect **QTNs**, raw score \n",
    "\n",
    "**baypass_2.1_PRUNED_BF_env :** GEA method to detect **QTNs**\n",
    "\n",
    "**baypass_2.1_PRUNED_XTX :** differentiation outlier method to detect **QTNs**, shows signal at inversion in certain scenarios\n",
    "\n",
    "**OutFLANK_0.2_PRUNED_log10p :** differentiation outlier method to detect **QTNs**, shows signal at inversion in certain scenarios\n",
    "\n",
    "**tajD :** ratio of pairwise differences to number of segregating sites. Detects positive selection\n",
    "\n",
    "**pi :** sequence diversity\n",
    "\n",
    "**thetaW :** Watterson's theta. Measure of diversity based on number of segregating sites\n",
    "\n",
    "**ihs :** integrated haplotype score\n",
    "\n",
    "**nsl :** number of segregating sites by length\n",
    "\n",
    "**H12 :** Garud's H statistics\n",
    "\n",
    "**H2/H1 :** quotient of Garud's H statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# readFeatures \n",
    "\n",
    "A subroutine that takes the name of a file. It returns a pandas dataframe of the data contained in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFeatures(file):\n",
    "    # initialize dataframe with _Invers_scanResults file\n",
    "    featDf =  pd.read_csv(file, sep = \" \")\n",
    "    \n",
    "    regex  = re.compile('/.*/[0-9]+_')             # regex to get the file path and number\n",
    "    m      = regex.match(file)\n",
    "    \n",
    "    # add the corresponding LEA results file to the dataframe\n",
    "    LEAf     = m.group() + \"Invers_Results_LEA.txt\"\n",
    "    LEAfeats = []\n",
    "    with open(LEAf, 'r') as f:\n",
    "        for line in f:\n",
    "            features = line.split()\n",
    "            features = [f.strip('\"') for f in features]\n",
    "            LEAfeats.append(features)\n",
    "        stats  = LEAfeats[1:]\n",
    "        header = LEAfeats[0]\n",
    "        LEAdf =  pd.DataFrame(stats, columns = header)\n",
    "\n",
    "    # add the corresponding RDA loadings to the dataframe\n",
    "    rdaVegF = m.group() + \"Invers_RDA_loadings_envi.txt\"\n",
    "    vegFeats = []\n",
    "    with open(rdaVegF, 'r') as f:    \n",
    "        for line in f:\n",
    "            features = line.split()\n",
    "            features = [f.strip('\"') for f in features]\n",
    "            vegFeats.append(features)\n",
    "        stats  = vegFeats[1:]\n",
    "        header = vegFeats[0]\n",
    "        header = [h.replace(\"position\", \"pos\") for h in header]\n",
    "        vegDf =  pd.DataFrame(stats, columns = header)\n",
    "    \n",
    "    # add the corresponding baypass results to the dataframe\n",
    "    baypassF = m.group() + \"baypass_results.txt\"\n",
    "    baypassFeats = []\n",
    "    with open(baypassF, 'r') as f:    \n",
    "        for line in f:\n",
    "            features = line.split()\n",
    "            features = [f.strip('\"') for f in features]\n",
    "            baypassFeats.append(features)\n",
    "        stats  = baypassFeats[1:]\n",
    "        header = baypassFeats[0]\n",
    "        baypassDf = pd.DataFrame(stats, columns = header)\n",
    "    \n",
    "    featDf = pd.concat([featDf, vegDf.drop(columns = ['pos']), \n",
    "                        baypassDf.drop(columns = ['pos']), LEAdf], sort = False, axis = 1)\n",
    "    return featDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitAndWrite\n",
    "\n",
    "splitAndWrite takes the list of features, splits it based on the genetic map, and writes the information to the appropriate file. The output file is what will be used as the feature vector in classfication\n",
    " \n",
    " Inputs: \n",
    "          \n",
    "      (1) Contents of a scan results file in list format with only relevant stats included\n",
    "      (2) boolean indicating whether this is the first file being processed\n",
    " Outputs: 7 files corresponding to the genetic map decribed below. Each line of the file is the statistics for one simulation.\n",
    " \n",
    "      (1) Neutral                   (chromosomes 1 and 10)\n",
    "      (2) QTL allowed to evolve     (chromosomes 2 and 3)\n",
    "      (3) Recent selective sweep    (chromosome 4)\n",
    "      (4) Background selection      (chromosomes 5 and 6)\n",
    "      (5) Central neutral inversion (chromosome 7)\n",
    "      (6) low recombination         (chromosome 8)\n",
    "      (7) Variable recombination    (chromosome 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitAndWrite(features, outdir):\n",
    "    ### remove chr 9 because it is variable and would throw off results\n",
    "    grouped = features.groupby('chrom')\n",
    "    features = features.drop(grouped.get_group(9).index)\n",
    "    \n",
    "    # scale stats across whole genome\n",
    "    scaledFeatures = features[stats].transform(scaleStats)\n",
    "    \n",
    "    # add class labels\n",
    "    scaledFeatures.insert(loc = 0, column = 'classLabel', \n",
    "                          value = features.apply(findLabel, axis = 1))\n",
    "    \n",
    "    # add pos and prop back in to locate QTNs of large and small effect\n",
    "    scaledFeatures.insert(loc = 0, column = 'pos', value = features['pos'].astype(\"float\"))\n",
    "    scaledFeatures.insert(loc = 0, column = 'prop', value = pd.to_numeric(features['prop'], errors = \"coerce\"))\n",
    "    \n",
    "    ## add labels to the SNPs within 200bp of a QTN\n",
    "    smallQTNs = scaledFeatures[((scaledFeatures['classLabel'] == 'MT=QTN_R=neutral') & \n",
    "                               (scaledFeatures['prop'] < .2))]['pos']\n",
    "\n",
    "    largeQTNs = scaledFeatures[((scaledFeatures['classLabel'] == 'MT=QTN_R=neutral') & \n",
    "                               (scaledFeatures['prop'] >= .2))]['pos']\n",
    "    \n",
    "    scaledFeatures.loc[scaledFeatures['pos'].isin(smallQTNs), 'classLabel'] = 'MT=smQTN_R=smQTNlink'\n",
    "    scaledFeatures.loc[scaledFeatures['pos'].isin(largeQTNs), 'classLabel'] = 'MT=lgQTN_R=lgQTNlink'\n",
    "\n",
    "    for site in smallQTNs:\n",
    "        lower = site - 200\n",
    "        upper = site + 200\n",
    "        scaledFeatures.loc[(scaledFeatures['pos'].between(lower, upper, inclusive = True)) & \n",
    "                        (scaledFeatures['pos'] != site), 'classLabel'] = 'MT=neut_R=smQTNlink'\n",
    "    for site in largeQTNs:\n",
    "        lower = site - 200\n",
    "        upper = site + 200\n",
    "        scaledFeatures.loc[(scaledFeatures['pos'].between(lower, upper, inclusive = True)) &\n",
    "                        (scaledFeatures['pos'] != site),'classLabel'] = 'MT=neut_R=lgQTNlink'\n",
    "   \n",
    "    ## drop the positions and props and write to file by group\n",
    "    scaledFeatures = scaledFeatures.drop(columns = ['pos', 'prop'])\n",
    "    labelGrouped   = scaledFeatures.groupby('classLabel')\n",
    "    for name, group in labelGrouped:\n",
    "        outfile     = outdir + \"/\" + name + \".fvec\"\n",
    "        outfile     = outfile.replace(\"=\", \"-\")\n",
    "        fileExists  = os.path.exists(outfile)            # does the file already exist?\n",
    "        \n",
    "        missingVals = np.where(group.applymap(lambda x: x == ''))\n",
    "        assert missingVals[0].size == 0, \"missing values at {} in {}\".format(missingVals, name)\n",
    "        \n",
    "        if fileExists:\n",
    "            group.to_csv(outfile, sep = '\\t', index = False, mode = 'a', header = False, na_rep = \"NA\")\n",
    "        else:\n",
    "            print(\"creating \" + outfile)\n",
    "            group.to_csv(outfile, sep = '\\t', index = False, mode = 'w', header = True, na_rep = \"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaleStats\n",
    "\n",
    "A function that takes a pandas series and scales it so that all entries are positive numbers between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleStats(statSeries):\n",
    "    #### some of the values for pcadaptlog10p were 'Inf'. This breaks some of the math, so I replaced the values\n",
    "    #### with a very large log10p value of 400, which represents an p-value extremely close to 0 and lower than \n",
    "    #### any of the non-Inf p-values\n",
    "    statSeries = statSeries.astype(str).str.replace(\"inf\", \"400\", case = False)\n",
    "    statSeries = pd.to_numeric(statSeries, errors = 'coerce')\n",
    "\n",
    "    # if there are any negative values, scale by addition first\n",
    "    minStat = statSeries.min()\n",
    "    if minStat < 0: \n",
    "        statSeries = statSeries + minStat\n",
    "    \n",
    "    # scale by dividing values by the sum\n",
    "    if statSeries.sum() != 0:\n",
    "        return(statSeries.divide(statSeries.sum(), fill_value = 0))\n",
    "    else:\n",
    "        return(statSeries.replace(np.nan, 0))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# findLabel\n",
    "findLabel is a simple function that takes the position and the muttype of an SNP and uses what we know about the \n",
    "genetic map to assign the SNP a label. Here is an example label:\n",
    "\n",
    "'MT=neut_R=invers'\n",
    "\n",
    "MT is just the muttype, taken directly from the scan results file. R stands for region, and it will be neutral unless the position is in an inversion, subject to background selection, or in a region of low recombination. This example label is a snp with \"MT=1\" and a position that is in the inversion, which is between 320000 and 330000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLabel(statSeries):\n",
    "    pos = statSeries['pos']\n",
    "    muttype = statSeries['muttype']\n",
    "    # 1 = neut, 2 = QTN, 3 = delet, 4 = sweep\n",
    "    muttypes = {\"MT=1\" : \"neut\", \n",
    "                \"MT=2\" : \"QTN\",\n",
    "                \"MT=3\" : \"delet\",\n",
    "                \"MT=4\" : \"sweep\",\n",
    "                \"MT=5\" : \"neut\"}         ### MT=5 is a artifact from SLiM to preserve the inversion\n",
    "    try:\n",
    "        mtLabel = muttypes[muttype]\n",
    "    except KeyError:\n",
    "        warnings.warn(\"Unknown muttype \" + muttype)\n",
    "        mtLabel = \"INVALID\"\n",
    "    \n",
    "    pos = float(pos)\n",
    "    if  200001 <= pos <= 230000 or  270001 <= pos <= 280000:\n",
    "        region = \"BS\"\n",
    "    elif 174000 <= pos <= 176000:\n",
    "        region = \"NearSS\"\n",
    "    elif 173000 <= pos <= 17399 or 176001 <= pos <= 177000:\n",
    "        region = \"FarSS\"\n",
    "    elif 320000 <= pos <= 330000:\n",
    "        region = \"invers\"\n",
    "    elif 370000 <= pos <= 380000:\n",
    "        region = \"lowRC\"\n",
    "    else:\n",
    "        region = \"neutral\"\n",
    "    return \"MT=\" + mtLabel + \"_R=\" + region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of Labels\n",
    "\n",
    "possible muttypes:\n",
    "\n",
    " - neutral\n",
    " - QTN         : can be either large effect (>.20 of variation in phenotype) or small effect (<.20 of variation)\n",
    " - deleterious : mutation that negatively effects fitness\n",
    " - sweep       : mutation that has become fixed and is expected to show evidence of a selective sweep around it\n",
    "\n",
    "possible regions:\n",
    "\n",
    " - Background selection : any SNP in the 10,000bp region where deleterious mutations occurred \n",
    " - Near Selective Sweep : within 1,000bp of the selective sweep\n",
    " - Far Selective Sweep  : 1,000-2,000bp from the selective sweep\n",
    " - large QTN linked     : within 200bp of a QTN of large effect\n",
    " - small QTN linked     : within 200bp of a QTN of small effect\n",
    " - inversion            : in an inversion\n",
    " - low recombination    : in a region of low recombination\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10900_Invers_ScanResults_with_sk-allel.txt\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-delet_R-BS.fvec\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-lgQTN_R-lgQTNlink.fvec\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-neut_R-BS.fvec\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-neut_R-FarSS.fvec\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-neut_R-NearSS.fvec\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-neut_R-invers.fvec\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-neut_R-lgQTNlink.fvec\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-neut_R-lowRC.fvec\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-neut_R-neutral.fvec\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-neut_R-smQTNlink.fvec\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-smQTN_R-smQTNlink.fvec\n",
      "creating /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A/MT-sweep_R-NearSS.fvec\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10901_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10902_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10903_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10904_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10905_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10906_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10907_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10908_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10909_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10910_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10911_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10912_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10913_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10914_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10915_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10916_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10917_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10918_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10919_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10920_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10922_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10923_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10924_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10925_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10927_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10928_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10929_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10930_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10931_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10932_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10933_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10934_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10935_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10936_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10937_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10938_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10939_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10940_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10941_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10942_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10943_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10944_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10945_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10946_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10947_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10948_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10949_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10950_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10951_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10952_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10953_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10954_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10955_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10956_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10957_Invers_ScanResults_with_sk-allel.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10958_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10959_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10960_Invers_ScanResults_with_sk-allel.txt\n",
      "Processing: /media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/results_final/10961_Invers_ScanResults_with_sk-allel.txt\n"
     ]
    }
   ],
   "source": [
    "subprocess.call([\"mkdir\", \"-p\", outDir])\n",
    "listOutFiles = \"ls \" + outDir\n",
    "outfileList =  subprocess.run(listOutFiles, shell = True, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "if len(outfileList) != 0:\n",
    "    warnings.warn(\"Out directory already contains files. They will be appended to and not overwritten\")\n",
    "    \n",
    "for f in fileList:\n",
    "    print(\"Processing: \" + f)\n",
    "    features = readFeatures(f)\n",
    "    splitAndWrite(features, outDir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
