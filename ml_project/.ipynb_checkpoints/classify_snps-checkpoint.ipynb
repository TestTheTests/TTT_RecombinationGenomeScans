{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, random\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import model_selection, preprocessing\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn import svm\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MT-delet_R-BS.fvec', 'MT-lgQTN_R-lgQTNlink.fvec', 'MT-neut_R-BS.fvec', 'MT-neut_R-FarSS.fvec', 'MT-neut_R-invers.fvec', 'MT-neut_R-lgQTNlink.fvec', 'MT-neut_R-lowRC.fvec', 'MT-neut_R-NearSS.fvec', 'MT-neut_R-neutral.fvec', 'MT-neut_R-smQTNlink.fvec', 'MT-smQTN_R-smQTNlink.fvec', 'MT-sweep_R-NearSS.fvec']\n"
     ]
    }
   ],
   "source": [
    "trainingSetDir = \"/media/kevin/TOSHIBA_EXT/TTT_RecombinationGenomeScans/ml_project/feature_vecs_all_SK-A\"\n",
    "classifierPickleFileName = \"all_sk-a_stats.p\"\n",
    "statsToUse = \"all\"\n",
    "print(os.listdir(trainingSetDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using these features: all (indices: range(1, 23))\n"
     ]
    }
   ],
   "source": [
    "classList = []\n",
    "trainingData = []\n",
    "labelToClassName = {}\n",
    "headerH = {}\n",
    "\n",
    "for trainingSetFileName in os.listdir(trainingSetDir):\n",
    "    classList.append(trainingSetFileName.split(\".fvec\")[0])\n",
    "    trainingSetFile = open(trainingSetDir + \"/\" + trainingSetFileName)\n",
    "    currTrainingData = trainingSetFile.readlines()\n",
    "    trainingSetFile.close()\n",
    "\n",
    "    trainingData += currTrainingData[1:]#append all training data from the current set (minus the header)\n",
    "\n",
    "    currLabelH = {}\n",
    "    for example in currTrainingData[1:]:\n",
    "        currLabelH[example.split(\"\\t\")[0]] = 1\n",
    "    assert len(currLabelH) == 1, \"Length: %d  label: %s\" %(len(currLabelH), currLabelH)\n",
    "    labelToClassName[list(currLabelH.keys())[0]] = trainingSetFileName.split(\".fvec\")[0]\n",
    "    \n",
    "    header = currTrainingData[0].strip().split(\"\\t\")\n",
    "    headerH[currTrainingData[0].strip()] = 1\n",
    "    assert header[0] == \"classLabel\"\n",
    "    statIndices = []\n",
    "    if \"all\" in statsToUse:\n",
    "        statIndices = range(1, len(header))\n",
    "    else:\n",
    "        for i in range(1, len(header)):\n",
    "            if header[i] in statsToUse or header[i].split(\"_win\")[0] in statsToUse:\n",
    "                statIndices.append(i)\n",
    "assert len(headerH) == 1\n",
    "\n",
    "sys.stderr.write(\"using these features: %s (indices: %s)\\n\" %(str(statsToUse), str(statIndices)))\n",
    "XH = {}\n",
    "for i in range(len(trainingData)):\n",
    "    trainingData[i] = trainingData[i].strip().split(\"\\t\")\n",
    "    currVector = []\n",
    "    if not \"nan\" in trainingData[i]:\n",
    "        for j in statIndices:\n",
    "            try:\n",
    "                currVector.append(float(trainingData[i][j]))\n",
    "            except:\n",
    "                print(\"Invalid data at coordinates: \" + str(i) + \",\" + str(j))\n",
    "                surr = trainingData[i-1 : i + 5]\n",
    "                for site in surr: print(site)\n",
    "                print(trainingData[i])\n",
    "                print(header[j])\n",
    "        assert len(currVector) == len(statIndices), \\\n",
    "        \"length of current vector: %s doesn't match length of stat indices: %s\" %(len(currVector), len(statIndices))\n",
    "        if trainingData[i][0] not in XH:\n",
    "            XH[trainingData[i][0]] = []\n",
    "        XH[trainingData[i][0]].append(currVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT=delet_R=BS            :    379\n",
      "MT=lgQTN_R=lgQTNlink     :     86\n",
      "MT=neut_R=BS             :  31197\n",
      "MT=neut_R=FarSS          :    585\n",
      "MT=neut_R=NearSS         :    983\n",
      "MT=neut_R=invers         :  11920\n",
      "MT=neut_R=lgQTNlink      :    502\n",
      "MT=neut_R=lowRC          :   8644\n",
      "MT=neut_R=neutral        : 312608\n",
      "MT=neut_R=smQTNlink      :   3511\n",
      "MT=smQTN_R=smQTNlink     :    639\n",
      "MT=sweep_R=NearSS        :     53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training set size after split: 6170\n",
      "Testing set size: 2057\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for classLabel in sorted(XH.keys()):\n",
    "    print('{:24} : {:>6}'.format(classLabel, str(len(XH[classLabel]))))\n",
    "    random.shuffle(XH[classLabel])\n",
    "    for i in range(1000):\n",
    "        try:\n",
    "            currVector = XH[classLabel][i]\n",
    "        except IndexError:\n",
    "            break\n",
    "        X.append(currVector)\n",
    "        y.append(classLabel)\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "sys.stderr.write(\"Training set size after split: %s\\n\" %(len(y_train)))\n",
    "sys.stderr.write(\"Testing set size: %s\\n\" %len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['MT=delet_R=BS', 'MT=lgQTN_R=lgQTNlink', 'MT=neut_R=BS', 'MT=neut_R=FarSS', 'MT=neut_R=invers', 'MT=neut_R=lgQTNlink', 'MT=neut_R=lowRC', 'MT=neut_R=NearSS', 'MT=neut_R=neutral', 'MT=neut_R=smQTNlink', 'MT=smQTN_R=smQTNlink', 'MT=sweep_R=NearSS'])\n"
     ]
    }
   ],
   "source": [
    "print(XH.keys())\n",
    "labels = XH.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    scores = pd.DataFrame(grid_scores)\n",
    "    top_scores = scores.sort_values(by = ['mean_test_score'], ascending = False).iloc[:n_top]\n",
    "    \n",
    "    for i in range(len(top_scores)):\n",
    "        score = top_scores.iloc[i]\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean test score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_test_score,\n",
    "              score.std_test_score))\n",
    "        print(\"Parameters: {0}\".format(score.params))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking accuracy when distinguishing among all 12 classes\n",
      "Training extraTreesClassifier\n",
      "GridSearchCV took 1096.20 seconds for 24 candidate parameter settings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for extraTreesClassifier\n",
      "Model with rank: 1\n",
      "Mean test score: 0.552 (std: 0.016)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 22, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean test score: 0.552 (std: 0.012)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 22, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean test score: 0.551 (std: 0.011)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 22, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['all_sk-a_stats.p']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.stderr.write(\"Checking accuracy when distinguishing among all %s classes\\n\" %(len(XH.keys())))\n",
    "\n",
    "maxMaxFeatures = len(X[0])\n",
    "param_grid_forest = {\"max_depth\": [3, 10, None],\n",
    "              \"max_features\": [1, 3, int(maxMaxFeatures**0.5), maxMaxFeatures],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "clf, mlType, paramGrid = ExtraTreesClassifier(n_estimators=100), \"extraTreesClassifier\", param_grid_forest\n",
    "\n",
    "heatmap = []\n",
    "sys.stderr.write(\"Training %s\\n\" %(mlType))\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid_forest, cv=10,n_jobs=-1, return_train_score = False)\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "sys.stderr.write(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\\n\"\n",
    "      % (time() - start, len(grid_search.cv_results_)))\n",
    "print(\"Results for %s\" %(mlType))\n",
    "report(grid_search.cv_results_)\n",
    "joblib.dump((X_test, y_test, grid_search, list(XH.keys())), classifierPickleFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean test score: 0.559 (std: 0.018)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean test score: 0.557 (std: 0.018)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 20, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean test score: 0.557 (std: 0.015)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 20, 'min_samples_leaf': 3, 'min_samples_split': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(grid_search.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
