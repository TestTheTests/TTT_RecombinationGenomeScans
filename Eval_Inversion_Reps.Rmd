---
title: "Eval_Inversion_Reps"
author: "Katie Lotterhos"
date: "3/13/2018"
output: html_document
---
setwd("/Users/katie/Desktop/TestTheTests/TTT_RecombinationGenomeScans")

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages("ROCR")

library(tidyverse)
library(RSQLite)
library(dbplyr)
library(ROCR)
library(vcfR)

options(readr.show_progress=FALSE)
```

This markdown is structured so that new results can be easily added. Just look for the keywords "To add new results."

Your working directory should be set to "TTT_RecombinationGenomeScans"

Your new results table should have column headings `program_version_SNPset_statistic`

* For example, to if you ran the program OutFLANK v 0.2 and calculated FST, then your column name would be `OutFLANK_0.2_FST`. If you then calculated -log10 P-values for each locus using ALL the SNPs in the data to calculate the null parameters on the neutral distribution of FST, then your column name would be `OutFLANK_0.2_ALL_log10p`. If you had instead calculated -log10 P-values for each locus using ONLY A PRUNED SET of SNPs (e.g., thinned for linkage disequilibrium as described in the paper) to calculate the null parameters on the neutral distribution of FST, then your column name would be `OutFLANK_0.2_PRUNED_log10p`.

* The pruned set of quasi-independent SNPs are indicated in the column `quasi_indep`

Some things to understand about the structure of the files: 

The "Invers_ScanResults" files have all the loci in the .vcf file, as well as all causal mutations (some of which were filtered before they were put into the vcf file). 

* The column in this dataframe called `keep_loci` indicates whether the loci was in the vcf file. 
* The column called `unique` is a unique identifier for each locus. This identifier is recommended to be used for any programs that will take a locus name, as it will ensure that the dataframes are correctly merged.

The LEA and Baypass results give output in the same order as the loci in the vcf file. If you program output results in a different order, than you should be sure to re-order them for the code to work.

# Read in files

This chunk of code inputs the results files. Each time an additional program is run, a new set of output files are generated. Those files can be added to the pipeline below and merged with the existing files, then easily incoporated into the subsequent analyses.

Here is a list of the columns and descriptions:
"vcf_ord"                     
"pos.x"                      
"chrom"                       
"a_freq_old"                 
"muttype"                     
"unique"                     
"for_relatedness" # NEED TO ADD A SET SEED FOR THIS, OTHERWISE SLIGHT DIFFERENT VCF FILES WILL BE PRODUCED IF I RERUN THIS AND ALL RESULTS WILL HAVE TO BE RUN AGAIN.            
"a_freq_final"               
"keep_loci"                   
"simID"                      
"quasi_indep"                 
"Hscan_v1.3_H12"             
"pca_ALL_PC1_loadings"        
"pca_ALL_PC2_loadings"       
"pca_ALL_PC3_loadings"        
"pca_PRUNED_PC1_loadings"    
"pca_PRUNED_PC2_loadings"     
"pcadapt_3.0.4_ALL_chisq"    
"pcadapt_3.0.4_ALL_log10p"    
"pcadapt_3.0.4_PRUNED_log10p"
"OutFLANK_0.2_FST"            
"OutFLANK_0.2_He"            
"OutFLANK_0.2_ALL_log10p"     
"OutFLANK_0.2_PRUNED_log10p" 
"LFMM_ridge_0.0_ALL_log10p"   
"LFMM_lasso_0.0_ALL_log10p"  
"CHR"                         
"rehh_2.0.2_ALL_iHS"         
"rehh_2.0.2_ALL_log10p"       
"Spearmans_ALL_rho"          
"selCoef"                     
"originGen"                  
"freq_old"                    
"freq_final"                 
"pa2"                         
"prop"                       
"He"                          
"type"                       
"LEA_1.2.0_ALL_K3_log10p"     
"LEA_1.2.0_ALL_K3_z"         
"pos.y"                       
"baypass_2.1_ALL_BF_pheno"   
"baypass_2.1_ALL_BF_env"      
"baypass_2.1_ALL_XTX"        
"baypass_2.1_PRUNED_BF_pheno" 
"baypass_2.1_PRUNED_BF_env"  
"baypass_2.1_PRUNED_XTX" 


```{r}

inver_files = list.files("results_final", pattern = "Invers_ScanResults")
inver_simID <- substr(inver_files, 1, 5)

LEA_files = paste0(inver_simID, "_Invers_Results_LEA.txt")
Baypass_files = paste0(inver_simID, "_baypass_results.txt")
# To add new results, add a line of code here to get a list of the files

length(inver_files)
length(LEA_files)
length(Baypass_files)
# To add new results, add a line of code here to check that the number of files is the same as the number of simulations


x_all <- NULL
for (i in 1:length(inver_files)){
  print(inver_simID[i])
  ## Main results
  x1 <- read_delim(paste0("results_final/", inver_files[i]), delim=" ")
  x1$type = "Inversion"
  
  ## LEA results
  x1_LEA <- read_delim(paste0("results_final/", LEA_files[i]), delim=" ")
  if (sum(x1$keep_loci)!=nrow(x1_LEA)){
    print("Error: wrong number of loci in LEA file"
    )
  }
  x1_LEA$unique <- x1$unique[which(x1$keep_loci)]
  
  ## BayPass results
  x1_baypass <- read_delim(paste0("results_final/", Baypass_files[i]), delim="\t")
    if (sum(x1$keep_loci)!=nrow(x1_baypass)){
    print("Error: wrong number of loci in baypass file"
    )
  }
  x1_baypass$unique <- x1$unique[which(x1$keep_loci)]
  
  ### New Results
  ### To add new results, copy and paste this code (leave this example for others), and rename it using the same structure as above
  ### Make sure you choose the appropriate delimiter
  ### x1_new <- read_delim(paste0("results_final/", my_files[i]), delim=" ")
  ###  if (sum(x1$keep_loci)!=nrow(x1_new)){
  ###  print("Error: wrong number of loci in new file"
  ###  )
  ### }
  ### x1_new$unique <- x1$unique[which(x1$keep_loci)]
  
  ## Combine all tables
  x_final1 <- left_join(x1, x1_LEA, by="unique")
  x_final2 <- left_join(x_final1, x1_baypass, by="unique")
  x_final <- x_final2
  
  
  ### To add new results, reword this code and write a new example for others
  ### x_final3 <- left_join(x_final2, x1_new, by="unique")
  ### x_final <- x_final3
  ### rm(x_final1, x_final2, x_final3)
  
  if(nrow(x_final)!=nrow(x1)){
    print("Error in merging files, number of rows has changed")
  }
  x_all <- rbind(x_all, x_final)
  rm(x_final1, x_final2)
}

table(x_all$simID)
nlevels(factor(x_all$simID))

names(x_all)[2] <- "pos"

x_all
  # number of rows should be 414474
```


## Set up genetic map for figures
No need to edit any of this code if you are adding a new method
```{r}

### Color recombination regions ####
  lgs <- seq(50000, 500000, by=50000) # linkage groups recombination breakpoints 0.5
  lg_whereplot <- lgs - 25000
  r <- 1e-05
  r_low <- 1e-11
  r_med <- 1e-08
  r_var = 10^(-1*(rnorm(1000, mean=5, sd=2)))
  quantile(log10(r_var), probs = c(0.1, 0.9))
  
  # each chrom 50000 bp long
  # chrom 1 neutral r
  # chrom 2 QTL r
  # chrom 3 QTL r
  # chrom 4 sweep r
  # chrom 5, 6 background r
  # chrom 7 had inversion 320000-330000
  # chrom 8 had r_med 370000-380000
  # chrom 9 had recombination variation
  # chrom 10 neutral r
  
### Plot function

plot_layers <- function(y_head=0, y_arrows=c(1,0.25), thisSim=NULL, ...){

  polygon(x=c(220000, 230000, 230000, 220000),
          y = c(-10000, -10000, 100000, 100000),
          col=rgb(0,0,0,0.2), border=NA)
    # BS
  polygon(x=c(270000, 280000, 280000, 270000),
          y = c(-10000, -10000, 100000, 100000),
          col=rgb(0,0,0,0.2), border=NA)
    # BS
  
  polygon(x=c(320000, 330000, 330000, 320000),
          y = c(-10000, -10000, 100000, 100000),
          col=rgb(1,0,0,0.3), border=NA)
  # Inversion
  
  abline(v=lgs, col=adjustcolor("grey", 0.5))
  
  polygon(x=c(370000, 380000, 380000, 370000),
          y = c(-10000, -10000, 100000, 100000),
          col=rgb(0,0,1,0.3), border=NA)
  # Low Recomb region
  
  polygon(x=c(400000, 450000, 450000, 400000),
          y = c(-10000, -10000, 100000, 100000),
          col=rgb(0,0,1,0.1), border=NA)
  
  text(lg_whereplot, y = y_head, 
       labels = c("LG1\nNeut", "LG2\nQTL", "LG3\nQTL",
                  "LG4\nSS", "LG5\nBS",
                  "LG6\nBS", "LG7\nNeut\nInversion",
                  "LG8\n r=1e-08", "LG9\nr var", "LG10\nNeut"))
  
  
  ### Add QTLs and Sweep Location
  if(length(thisSim)>0){
  muts <- x_all %>% filter(simID==thisSim)
  arrows(muts$pos[muts$muttype=="MT=2"],  y_arrows[1], muts$pos[muts$muttype=="MT=2"],  y_arrows[2], col="orange", lwd=muts$prop[muts$muttype=="MT=2"]*10, length = 0.1)
  }
  
  arrows(175001, y_arrows[1], 175001, y_arrows[2], col="purple", lwd=2, length = 0.1)
} #end plot function

pdf("figures/InversionMap.pdf", width=12, height=4)
  par(mar=c(4,2,1,2))
  plot(0,0, col="white", xlim=c(0, 500000), ylim=c(-1,1), xaxs="i", yaxt="n", ylab="", xlab="Position (bp)")
  plot_layers()
dev.off()  
```


## Effect size and allele frequency
No need to edit this code if you are adding a new method
```{r effect size a_freq}

head(x_all)
levels(factor(x_all$simID))
nlevels(factor(x_all$simID))
sum(is.na(x_all$simID))
  
  mean(tapply(x_all$simID, x_all$simID, length)) # ave number of SNPs after filtering
  
    mean(tapply(x_all$prop>=0.01, x_all$simID, sum, na.rm=TRUE)) # ave number of SNPs after filtering
    
    # check that AGV sums to 1 for all simulations
    tapply(x_all$prop, x_all$simID, sum, na.rm=TRUE)
      # all mutations here
    mean(tapply(x_all$prop, x_all$simID, max, na.rm=TRUE)) # ave effect size of max SNP
    
    #x <- x_all[which(x_all$simID==10903 & x_all$muttype=="MT=2"),]#& x_all$keep_loci==FALSE & x_all$count==TRUE),]
  
  # check no NA's
  sum(is.na(x_all$keep_loci))
  sum(is.na(x_all$a_freq_final))
    
  countbutnotinfinal <- which(x_all$keep_loci==FALSE & x_all$prop>=0.01 & x_all$muttype=="MT=2") # rare alleles of large effect
  keepcount<- which(x_all$keep_loci==TRUE & x_all$prop>=0.01 & x_all$muttype=="MT=2")  # common alleles of large effect
  dontkeepdontcount <- which(x_all$keep_loci==FALSE & x_all$prop<0.01 & x_all$muttype=="MT=2") # rare alleles small effect
  keepdontcount <- which(x_all$keep_loci==TRUE & x_all$prop<0.01 & x_all$muttype=="MT=2")
    # common alleles of small effect
  
  #sanity check
    sum(x_all$muttype=="MT=2") # number of M2 mutations
    length(c( countbutnotinfinal, keepcount, dontkeepdontcount, keepdontcount))
    # these should be equal

  length(countbutnotinfinal)
    # $keep_loci means they were not in the final vcf file

  mean(x_all$prop[countbutnotinfinal], na.rm=TRUE)

pdf("figures/PlotFreqVsEffectSize.pdf", width=7, height=9)
  par(mfrow=c(2,1), mar=c(3,3,1,1), oma=c(3,3,0,0))
  
    # common causal alleles
    plot(x_all$a_freq_final[keepcount], abs(x_all$selCoef[keepcount]), col=adjustcolor("#F0AE2D", 0.5), pch=19, ylim=c(0,3.2), ylab="", xlab="")

    # rare causal alleles of smaller effect
    points(x_all$a_freq_final[dontkeepdontcount], abs(x_all$selCoef[dontkeepdontcount]), pch=2, col=adjustcolor("#0067E5", 0.5))
    
    # common causal alleles of smaller effect
    points(x_all$a_freq_final[keepdontcount], abs(x_all$selCoef[keepdontcount]), pch=1, col=adjustcolor("#00397F", 0.5))
    
    # rare causal alleles of larger effect
    points(x_all$a_freq_final[countbutnotinfinal], abs(x_all$selCoef[countbutnotinfinal]), pch=17, col=adjustcolor("#B27600", 0.5))
  
  # zoom in on x-axis
      legend(0.3,3, c("Common alleles > 1% AGV", "Common alleles < 1% AGV", "Rare alleles > 1% AGV", "Rare alleles < 1% AGV"), pch=c(19,1, 17, 2), col=c("#F0AE2D", "#00397F", "#B27600", "#0067E5"),bty="n")
      
    plot(x_all$a_freq_final[keepcount], abs(x_all$selCoef[keepcount]), col=adjustcolor("#F0AE2D", 0.5), pch=19, ylim=c(0,3.2), ylab="", xlab="", xlim=c(0,0.02))
    points(x_all$a_freq_final[dontkeepdontcount], abs(x_all$selCoef[dontkeepdontcount]), pch=2, col=adjustcolor("#0067E5", 0.5))
    points(x_all$a_freq_final[keepdontcount], abs(x_all$selCoef[keepdontcount]), pch=1, col=adjustcolor("#00397F", 0.5))
    points(x_all$a_freq_final[countbutnotinfinal], abs(x_all$selCoef[countbutnotinfinal]), pch=17, col=adjustcolor("#B27600", 0.5))
    abline(v = 0.01, col="grey")
    text(0.075,3.1, "Zoom in on x-axis")
    mtext("Frequency", 1, outer=TRUE)
    mtext("Effect Size", 2, outer=TRUE)
  dev.off()

# For each simulation, let's see how much genetic variance remains unexplained by causal loci that are not in the final dataset, but contribute more than 1% to AGV
    # these are rare loci of large effect
  (totAGV_rareLarge <- 
   tapply(x_all$prop[countbutnotinfinal], x_all$simID[countbutnotinfinal], sum, na.rm=TRUE))
   (totAGV_rareLargenum <- tapply(x_all$prop[countbutnotinfinal], x_all$simID[countbutnotinfinal], length)) # note this doesn't include 0s
  
    # supp figure
  #quantile(totAGV_rareLarge, c(0.025, 0.975))
  # on average 17% of genetic variance remains unexplained by causal loci not in the final dataset
  
# For each simulation, let's see how much genetic variance remains unexplained by causal loci that are not in the final dataset, and contribute LESS than 1% to AGV
  # rare alleles of small effect
  (totAGV_rareSmall <-   tapply(x_all$prop[dontkeepdontcount], x_all$simID[dontkeepdontcount], sum, na.rm=TRUE))
   (totAGV_rareSmallNum <-   tapply(x_all$prop[dontkeepdontcount], x_all$simID[dontkeepdontcount], length))
  
    (totAGV_commonSmall <-   tapply(x_all$prop[keepdontcount], x_all$simID[keepdontcount], sum, na.rm=TRUE))
  (totAGV_commonSmallNum <-   tapply(x_all$prop[keepdontcount], x_all$simID[keepdontcount], length))
  
# For each simulation, let's see how much genetic variance is explained by common alleles that are in the dataset
  (totAGV_common <-   tapply(x_all$prop[keepcount], x_all$simID[keepcount], sum, na.rm=TRUE))
   (totAGV_commonNum <-   tapply(x_all$prop[keepcount], x_all$simID[keepcount], length))
  

  totAGV <- data.frame(simID=names(totAGV_common), totAGV_common, totAGV_commonNum, totAGV_rareSmall, totAGV_rareSmallNum) %>% merge( data.frame(simID=names(totAGV_rareLarge), totAGV_rareLarge, totAGV_rareLargenum), all.x=TRUE) %>% merge( data.frame(simID=names(totAGV_commonSmall), totAGV_commonSmall, totAGV_commonSmallNum), all.x=TRUE) 
  totAGV$sum <- rowSums(totAGV[,c(2,4,6,8)], na.rm=TRUE)  
  totAGV[is.na(totAGV)] <- 0
  apply(totAGV[,2:10], 2, quantile, c(0.05, 0.5, 0.95, 1.0))
  totAGV
  
   
# Make a plot of histograms
  pdf("figures/PropAGVacrossSims.pdf", width=5, height = 4)
  #par(mfrow=c(3,1))
  #hist(totAGV_rareSmall, breaks=seq(0,1,0.05))
  #hist(totAGV_rareLarge, breaks=seq(0,1,0.05))
  #hist(totAGV_common, breaks=seq(0,1,0.05)) 
    par(mfrow=c(1,1), mar=c(3,4,1,1), oma=c(3,0,0,0))
    barplot(rbind(totAGV$totAGV_common, totAGV$totAGV_rareLarge, 
                  totAGV$totAGV_commonSmall, totAGV$totAGV_rareSmall), 
                  col=c("#F0AE2D","#B27600" , "#00397F", "#0067E5"),  
                  ylab="Proportion of additive genetic variance", 
                  names.arg = rep("", nrow(totAGV)))
    mtext("Simulation replicate", 1)
    par(fig = c(0, 1, 0, 1), oma = c(0, 1, 0, 1), mar = c(3, 4, 1, 4), new = TRUE)
    plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n", ylab="", xlab="")
    legend("bottom", c("Common alleles", "Rare alleles\nlarge effect", "Common alleles\nsmall effect", "Rare alleles\nsmall effect"), xpd = TRUE, horiz = TRUE, inset = c(0, 0), bty = "n",  fill= c("#F0AE2D","#B27600" , "#00397F", "#0067E5"), cex =0.7, border="black")
  dev.off()
```

### Multiplot function
copied from cookbook for R. 

No need to edit this code if you are adding a new method.
```{r}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}



shaded.bxp <- function (z, notch = FALSE, width = NULL, varwidth = FALSE, outline = TRUE, 
    notch.frac = 0.5, log = "", border = par("fg"), pars = NULL, 
    frame.plot = axes, horizontal = FALSE, add = FALSE, at = NULL, 
    show.names = NULL, density=NULL, angle=45,  ...) 
{ 
    pars <- c(list(...), pars) 
    pars <- pars[unique(names(pars))] 
    bplt <- function(x, wid, stats, out, conf, notch, xlog, i, density, angle=45, boxfill) { 
        ok <- TRUE 
        if (!any(is.na(stats))) { 
            xP <- if (xlog) 
                function(x, w) x * exp(w) 
            else function(x, w) x + w 
            wid <- wid/2 
            if (notch) { 
                ok <- stats[2L] <= conf[1L] && conf[2L] <= stats[4L] 
                xx <- xP(x, wid * c(-1, 1, 1, notch.frac, 1, 
                  1, -1, -1, -notch.frac, -1)) 
                yy <- c(stats[c(2, 2)], conf[1L], stats[3L], 
                  conf[2L], stats[c(4, 4)], conf[2L], stats[3L], 
                  conf[1L]) 
            } 
            else { 
                xx <- xP(x, wid * c(-1, 1, 1, -1)) 
                yy <- stats[c(2, 2, 4, 4)] 
            } 
            if (!notch) 
                notch.frac <- 1 
            wntch <- notch.frac * wid 
            xypolygon(xx, yy, lty = "blank", col = boxfill[i], density=density[i], angle=angle[i]) 
            xysegments(xP(x, -wntch), stats[3L], xP(x, +wntch), 
                stats[3L], lty = medlty[i], lwd = medlwd[i], 
                col = medcol[i], lend = 1) 
            xypoints(x, stats[3L], pch = medpch[i], cex = medcex[i], 
                col = medcol[i], bg = medbg[i]) 
            xysegments(rep.int(x, 2), stats[c(1, 5)], rep.int(x, 
                2), stats[c(2, 4)], lty = whisklty[i], lwd = whisklwd[i], 
                col = whiskcol[i]) 
            xysegments(rep.int(xP(x, -wid * staplewex[i]), 2), 
                stats[c(1, 5)], rep.int(xP(x, +wid * staplewex[i]), 
                  2), stats[c(1, 5)], lty = staplelty[i], lwd = staplelwd[i], 
                col = staplecol[i]) 
            xypolygon(xx, yy, lty = boxlty[i], lwd = boxlwd[i], 
                border = boxcol[i], density=density[i], angle=angle[i], col=boxfill[i]) 
            if ((nout <- length(out))) { 
                xysegments(rep(x - wid * outwex, nout), out, 
                  rep(x + wid * outwex, nout), out, lty = outlty[i], 
                  lwd = outlwd[i], col = outcol[i]) 
                xypoints(rep.int(x, nout), out, pch = outpch[i], 
                  lwd = outlwd[i], cex = outcex[i], col = outcol[i], 
                  bg = outbg[i]) 
            } 
            if (any(inf <- !is.finite(out))) { 
                warning(sprintf(ngettext(length(unique(out[inf])), 
                  "Outlier (%s) in boxplot %d is not drawn", 
                  "Outliers (%s) in boxplot %d are not drawn"), 
                  paste(unique(out[inf]), collapse = ", "), x), 
                  domain = NA) 
            } 
        } 
        return(ok) 
    } 
    if (!is.list(z) || 0L == (n <- length(z$n))) 
        stop("invalid first argument") 
    if (is.null(at)) 
        at <- 1L:n 
    else if (length(at) != n) 
        stop("'at' must have same length as 'z$n', i.e. ", n) 
    if (is.null(z$out)) 
        z$out <- numeric() 
    if (is.null(z$group) || !outline) 
        z$group <- integer() 
    if (is.null(pars$ylim)) 
        ylim <- range(z$stats[is.finite(z$stats)], if (outline) z$out[is.finite(z$out)], 
            if (notch) z$conf[is.finite(z$conf)]) 
    else { 
        ylim <- pars$ylim 
        pars$ylim <- NULL 
    } 
    if (is.null(pars$xlim)) 
        xlim <- c(0.5, n + 0.5) 
    else { 
        xlim <- pars$xlim 
        pars$xlim <- NULL 
    } 
    if (length(border) == 0L) 
        border <- par("fg") 
    dev.hold() 
    on.exit(dev.flush()) 
    if (!add) { 
        plot.new() 
        if (horizontal) 
            plot.window(ylim = xlim, xlim = ylim, log = log, 
                xaxs = pars$yaxs) 
        else plot.window(xlim = xlim, ylim = ylim, log = log, 
            yaxs = pars$yaxs) 
    } 
    xlog <- (par("ylog") && horizontal) || (par("xlog") && !horizontal) 
    pcycle <- function(p, def1, def2 = NULL) rep(if (length(p)) p else if (length(def1)) def1 else def2, 
        length.out = n) 
    p <- function(sym) pars[[sym, exact = TRUE]] 
    boxlty <- pcycle(pars$boxlty, p("lty"), par("lty")) 
    boxlwd <- pcycle(pars$boxlwd, p("lwd"), par("lwd")) 
    boxcol <- pcycle(pars$boxcol, border) 
    boxfill <- pcycle(pars$boxfill, par("bg")) 
    density <- rep(density, length.out=n) 
    density <- rep(density, length.out=n) 
    angle <- rep(angle, length.out=n) 
    boxwex <- pcycle(pars$boxwex, 0.8 * { 
        if (n <= 1) 
            1 
        else stats::quantile(diff(sort(if (xlog) 
            log(at) 
        else at)), 0.1) 
    }) 
    medlty <- pcycle(pars$medlty, p("lty"), par("lty")) 
    medlwd <- pcycle(pars$medlwd, 3 * p("lwd"), 3 * par("lwd")) 
    medpch <- pcycle(pars$medpch, NA_integer_) 
    medcex <- pcycle(pars$medcex, p("cex"), par("cex")) 
    medcol <- pcycle(pars$medcol, border) 
    medbg <- pcycle(pars$medbg, p("bg"), par("bg")) 
    whisklty <- pcycle(pars$whisklty, p("lty"), "dashed") 
    whisklwd <- pcycle(pars$whisklwd, p("lwd"), par("lwd")) 
    whiskcol <- pcycle(pars$whiskcol, border) 
    staplelty <- pcycle(pars$staplelty, p("lty"), par("lty")) 
    staplelwd <- pcycle(pars$staplelwd, p("lwd"), par("lwd")) 
    staplecol <- pcycle(pars$staplecol, border) 
    staplewex <- pcycle(pars$staplewex, 0.5) 
    outlty <- pcycle(pars$outlty, "blank") 
    outlwd <- pcycle(pars$outlwd, p("lwd"), par("lwd")) 
    outpch <- pcycle(pars$outpch, p("pch"), par("pch")) 
    outcex <- pcycle(pars$outcex, p("cex"), par("cex")) 
    outcol <- pcycle(pars$outcol, border) 
    outbg <- pcycle(pars$outbg, p("bg"), par("bg")) 
    outwex <- pcycle(pars$outwex, 0.5) 
    width <- if (!is.null(width)) { 
        if (length(width) != n | any(is.na(width)) | any(width <= 
            0)) 
            stop("invalid boxplot widths") 
        boxwex * width/max(width) 
    } 
    else if (varwidth) 
        boxwex * sqrt(z$n/max(z$n)) 
    else if (n == 1) 
        0.5 * boxwex 
    else rep.int(boxwex, n) 
    if (horizontal) { 
        xypoints <- function(x, y, ...) points(y, x, ...) 
        xypolygon <- function(x, y, ...) polygon(y, x, ...) 
        xysegments <- function(x0, y0, x1, y1, ...) segments(y0, 
            x0, y1, x1, ...) 
    } 
    else { 
        xypoints <- points 
        xypolygon <- polygon 
        xysegments <- segments 
    } 
    ok <- TRUE 
    for (i in 1L:n) ok <- ok & bplt(at[i], wid = width[i], stats = z$stats[, 
        i], out = z$out[z$group == i], conf = z$conf[, i], notch = notch, 
        xlog = xlog, i = i, density=density, angle=angle, boxfill=boxfill) 
    if (!ok) 
        warning("some notches went outside hinges ('box'): maybe set notch=FALSE") 
    axes <- is.null(pars$axes) 
    if (!axes) { 
        axes <- pars$axes 
        pars$axes <- NULL 
    } 
    if (axes) { 
        ax.pars <- pars[names(pars) %in% c("xaxt", "yaxt", "xaxp", 
            "yaxp", "las", "cex.axis", "col.axis", "format")] 
        if (is.null(show.names)) 
            show.names <- n > 1 
        if (show.names) 
            do.call("axis", c(list(side = 1 + horizontal, at = at, 
                labels = z$names), ax.pars)) 
        do.call("Axis", c(list(x = z$stats, side = 2 - horizontal), 
            ax.pars)) 
    } 
    do.call("title", pars[names(pars) %in% c("main", "cex.main", 
        "col.main", "sub", "cex.sub", "col.sub", "xlab", "ylab", 
        "cex.lab", "col.lab")]) 
    if (frame.plot) 
        box() 
    invisible(at) 
} 
```

### Evaluate population structure
 No need to edit this code if you are adding a new method
 
```{r}

thisim = 10944 #10903
forpdf <- x_all[x_all$simID==thisim,]
(inv_index <- which(forpdf$muttype=="MT=5"))

### PC scores of individuals ####
  # load individual data
  inddf <- read_delim(paste0("results_final/",
                             thisim,"_Invers_indFILT.txt"),
                      delim=" ")
  head(inddf)
  ind_geno <- read.vcfR(paste0("results_final/",
                             thisim, "_Invers_VCFallFILT.vcf.gz", sep=""))
  (inv_index <- grep("MT=5", ind_geno@fix[,"INFO"]))
  
  genoinv <- (ind_geno@gt[inv_index,-1])
  # check dimensions
    dim(inddf[which(inddf$infinal),])
    length(genoinv)
    genoinv[which(genoinv=="1|0")] <- "0|1" # set heterozygotes equal
    levels(factor(genoinv))
    library(RColorBrewer)
    myColors <- brewer.pal(3,"Set2")
    names(myColors) <- levels(factor(genoinv))
    colScale <- scale_colour_manual(name = "Inversion\ngenotype",values = myColors)
  
pdf("figures/PC_scores_compare.pdf", width=6, height=9)    
 
  # Individual scores without LD pruning
  p1 <- qplot(inddf$pca_ALL_PC1_scores[inddf$infinal], inddf$pca_ALL_PC2_scores[inddf$infinal],
        colour=genoinv, 
        main="A) Individual scores (all SNPs)") + 
    colScale + theme_bw() + xlab("PC1 score") + ylab("PC2 score")

  # Individual scores with LD pruning
  p2<- qplot(inddf$pca_PRUNED_PC1_scores, inddf$pca_PRUNED_PC2_scores,
        colour=inddf$envi, main="B) Individual scores (thinned SNPs)", xlab="PC1 score", ylab="PC2 score" ) + theme_bw() + labs(colour="Environm.") + scale_color_gradient2( low="blue", mid="white", high="red", space ="Lab" )
  
  multiplot(p1, p2, cols=1)
  dev.off()

### PC loadings of loci ####
par(mar=c(4,4,1,1))
plot(forpdf$pos, forpdf$pca_ALL_PC1_loadings,
     ylim=c(-8, 13),
      pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "PC1 loadings", xaxt="n")#, 
     #xlim=c(170000 , 180000))
  plot_layers(y_head=10, y_arrows=c(10000, 8000), thisSim = thisim)
  plot(forpdf$pos, forpdf$pca_ALL_PC2_loadings,
     ylim=c(-8, 13),
      pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "PC1 loadings", xaxt="n")#, 
     #xlim=c(170000 , 180000))
  plot_layers(y_head=10, y_arrows=c(10000, 8000), thisSim = thisim)
  
  plot(forpdf$pos, forpdf$pca_PRUNED_PC1_loadings,
     ylim=c(-8, 13),
      pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "PC1 loadings", xaxt="n")#, 
     #xlim=c(170000 , 180000))
  plot_layers(y_head=10, y_arrows=c(10, 8), thisSim = thisim)
  plot(forpdf$pos, forpdf$pca_PRUNED_PC2_loadings,
     ylim=c(-8, 13),xlim=c(0,5e05),
      pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "PC1 loadings", xaxt="n")#, 
     #xlim=c(170000 , 180000))
  plot_layers(y_head=10, y_arrows=c(10, 8), thisSim = thisim)
  
  ### which locations load onto PC all data ####
pdf("figures/WhichLocationsPCs.pdf", width=9, height=6)  
  par(mar=c(4, 4,1,1), oma=c(0,2,0,0), mfrow=c(3,1))
  d <- density(x_all$pos[which(abs(x_all$pca_ALL_PC1_loadings)>3)], bw = 1000)
  plot(d, main="A) Locations of outlier PC1 loadings (all SNPs)", bty="n", las=1, ylim=c(0, 13e-05), xlim=c(0,5e05),
       ylab="", xlab="")
  polygon(d, col="black")
  plot_layers(y_head=0.00011, y_arrows=c(10, 8), thisSim = thisim)
  
  d <- density(x_all$pos[which(abs(x_all$pca_ALL_PC2_loadings)>3)], bw = 1000)
    plot(d, main="B) Locations of outlier PC2 loadings (all SNPs)", bty="n", las=1, ylim=c(0, 6e-05), xlim=c(0,5e05),
       ylab="", xlab="")
  polygon(d, col="black")
  plot_layers(y_head=10, y_arrows=c(10, 8), thisSim = thisim)
  
  d <- density(x_all$pos[which(abs(x_all$pca_PRUNED_PC1_loadings)>3)], bw = 1000)
    plot(d, main="C) Locations of outlier PC1 loadings (trimmed SNPs)", bty="n", las=1, ylim=c(0, 2e-05), xlim=c(0,5e05),
       ylab="", xlab="Position (bp)")
  polygon(d, col="black")
  plot_layers(y_head=1.7e-05, y_arrows=c(10, 8), thisSim = thisim)
  
  mtext("Density", side = 2, outer=TRUE, line=0)
dev.off()  

```

### Visualize genome scans: Manhattan plots
This plot compares a few of the different methods, but is not comprehensive. Depending on the methods to be compared, the code could be copied and used to produce similar plots.

```{r}
thisim = 10944
# 10944 This is an interesting case when the inversion drifted to some diverse frequencies in a couple of the subpopulations, and resulted in a slightly elevated signal in the inversion. Note that this did not happen in many of the simulations.

# Note that the y-axes in the below graphs are specific to this simulation

forpdf <- x_all[x_all$simID==thisim,]

### Manahattan plot comparing selective sweep sims ###
pdf(paste0("figures/Manhattan_SS_",thisim,".pdf"), width=8, height= 4)
par(mfrow=c(2,1), mar=c(0.5, 4, 0.5,0.1), oma=c(3,0,0,0))
  
plot(forpdf$pos[forpdf$keep_loci], forpdf$Hscan_v1.3_H12[forpdf$keep_loci],
     ylim= c(0, 15000), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.7, ylab= "H12 (H-scan)", xaxt="n",  type="h", bty="l")#, 
     #xlim=c(170000 , 180000))
  plot_layers(y_head=12000, y_arrows=c(9500, 7600), thisSim = thisim)
  
  plot(forpdf$pos, forpdf$rehh_2.0.2_ALL_log10p,
     ylim= c(0, 6), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.7, ylab= "-log10(P) iHS",  type="h", bty="l")
  plot_layers(y_head=90, y_arrows=c(5.5, 4), thisSim=thisim)
  
  mtext("Position (bp)", side=1, outer=TRUE, line=2)
dev.off()
  
### Manahattan plot comparing Differentiation Outliers ###
pdf(paste0("figures/Manhattan_DO",thisim,".pdf"), width=8, height= 10)
par(mfrow=c(6,1), mar=c(0.5, 4, 2,0.1), oma=c(3,0,0,0))
  plot(forpdf$pos, forpdf$pcadapt_3.0.4_ALL_log10p,
      ylim= c(0, 500), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "-log10(P) PCAdapt Naive", xaxt="n", type="h", bty="l", main="A) PCAdapt Naive", adj=0)
  plot_layers(y_head=400, y_arrows=c(300, 200), thisSim = thisim)

  plot(forpdf$pos, forpdf$pcadapt_3.0.4_PRUNED_log10p,
     ylim= c(0, 43), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "-log10(P) PCAdapt B.P.", xaxt="n", type="h", bty="l", main="B) PCAdapt Best Practice", adj=0)
  plot_layers(y_head=380, y_arrows=c(41,33), thisSim=thisim)

  plot(forpdf$pos, forpdf$OutFLANK_0.2_ALL_log10p,
     ylim= c(0, 19), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "-log10(P) OutFLANK Naive", xaxt="n", type="h", bty="l", main="C) OutFLANK (Fst) Naive", adj=0)
  plot_layers(y_head=16, y_arrows=c(13.5,11), thisSim=thisim)

  plot(forpdf$pos, forpdf$OutFLANK_0.2_PRUNED_log10p,
     ylim= c(0, 19), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "-log10(P) OutFLANK B.P.", type="h", xaxt="n", bty="l", main="D) OutFLANK (Fst) Best Practice", adj=0)
  plot_layers(y_head=160, y_arrows=c(13.5,11), thisSim=thisim)
  
  plot(forpdf$pos, forpdf$baypass_2.1_ALL_XTX,
     ylim= c(25, 165), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "           XTX Naive", xaxt="n", type="h", bty="l", main="E) BayPass (XTX) Naive", adj=0)
  plot_layers(y_head=150, y_arrows=c(135,115), thisSim=thisim)

  plot(forpdf$pos, forpdf$baypass_2.1_PRUNED_XTX,
     ylim= c(25, 165), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "              XTX B.P.", type="h", bty="l", main="F) BayPass (XTX) Best Practice", adj=0)
  plot_layers(y_head=0, y_arrows=c(135,115), thisSim=thisim)
  
  mtext("Position (bp)", side=1, outer=TRUE, line=2)
dev.off()
  


### Manahattan plot comparing Association Tests ###

cor.test(x_all$baypass_2.1_ALL_BF_env, x_all$baypass_2.1_ALL_BF_pheno)
cor.test(x_all$baypass_2.1_ALL_BF_env, x_all$baypass_2.1_PRUNED_BF_env)
cor.test(x_all$baypass_2.1_PRUNED_BF_pheno, x_all$baypass_2.1_PRUNED_BF_env)
cor.test(x_all$baypass_2.1_PRUNED_BF_pheno, x_all$baypass_2.1_ALL_BF_pheno)
  # Results for environment and phenotype are very similar, just use one

summary(x_all$baypass_2.1_PRUNED_BF_pheno)
summary(x_all$baypass_2.1_PRUNED_BF_env)
summary(x_all$baypass_2.1_ALL_BF_pheno)
summary(x_all$baypass_2.1_ALL_BF_env)
summary(forpdf$baypass_2.1_ALL_BF_env)

pdf(paste0("figures/Manhattan_Assoc",thisim,".pdf"), width=8, height= 10)
par(mfrow=c(6,1), mar=c(0.5, 4, 2,0.1), oma=c(3,0,0,0))

plot(forpdf$pos, forpdf$LFMM_ridge_0.0_ALL_log10p,
     ylim= c(0, 150), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="A) LFMM ridge (phenotype)", adj=0, ylab="-log10 P (LFMM ridge)", xaxt="n")
plot_layers(y_head=130, y_arrows=c(120,100), thisSim=thisim)


plot(forpdf$pos, forpdf$LFMM_lasso_0.0_ALL_log10p,
     ylim= c(0, 140), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="B) LFMM lasso (phenotype)", adj=0, ylab="-log10 P (LFMM lasso)", xaxt="n")
plot_layers(y_head=-100, y_arrows=c(130,110), thisSim=thisim)

plot(forpdf$pos, forpdf$Spearmans_ALL_rho,
     ylim= c(0, 0.8), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="C) Spearman's rho (environment)", adj=0, ylab="     abs(Spearman's rho)", xaxt="n")
plot_layers(y_head=0.7, y_arrows=c(0.6, 0.45), thisSim=thisim)

plot(forpdf$pos, forpdf$LEA_1.2.0_ALL_K3_log10p,
     ylim= c(0, 70), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="D) LEA (environment)", adj=0, ylab="        -log10 P (LEA)", xaxt="n")
plot_layers(y_head=-10, y_arrows=c(60, 50), thisSim=thisim)

plot(forpdf$pos, forpdf$baypass_2.1_ALL_BF_env,
     ylim= c(-20, 90), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="E) BayPass Bayes Factor - Naive (environment)", adj=0, ylab="        Bayes Factor Naive", xaxt="n")
plot_layers(y_head=70, y_arrows=c(60, 50), thisSim=thisim)

plot(forpdf$pos, forpdf$baypass_2.1_PRUNED_BF_env,
     ylim= c(-20, 90), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="E) BayPass Bayes Factor - Best Practice (environment)", adj=0, ylab="               Bayes Factor B.P.")
plot_layers(y_head=-40, y_arrows=c(60, 50), thisSim=thisim)

mtext("Position (bp)", side=1, outer=TRUE, line=2)

dev.off()


```

### AUC

This section has some code that will need to be edited if results are added.

For programs designed to detect the global sweep, these are evaluated at the sweep only.

For programs designed to detect the loci that differ in allele frequency among populations, or loci that have an association with phenotype or environment, these are evaluated at the QTNs.

The overall evaluatation is based on Area Under the Curve (AUC).

```{r}

  # Loop through each statistic
  # Set up a list of predictions
label_list_QTN <- list()
x_all <- x_all %>% mutate(count_QTN = FALSE)
x_all$count_QTN[x_all$prop>=0.01] <- TRUE

label_list_SS <- list()
x_all <- x_all %>% mutate(count_SS = FALSE)
x_all$pos[x_all$muttype=="MT=4"]
x_all$count_SS[x_all$pos > (175001-2000) & x_all$pos < (175001+2000)] <- TRUE
tapply(x_all$count_SS,x_all$simID,  sum)

for (i in 1:length(inver_simID)){
  print(i)
  label_list_QTN[[i]] <- x_all$count_QTN[which(x_all$simID == inver_simID[i])]
  label_list_SS[[i]] <- x_all$count_SS[which(x_all$simID == inver_simID[i])]
}

# loop through columns of data

# To add results to the evaluation, add the names of the columns 
# in the x_all dataframe here
# in the order you would like to see them plotted
# (note that it is easy to remove columns for plotting)
togetcols <- c(
  ##SS methods
      "Hscan_v1.3_H12", "rehh_2.0.2_ALL_log10p", 
  ## DO methods             
      "pcadapt_3.0.4_ALL_log10p","pcadapt_3.0.4_PRUNED_log10p",
      "OutFLANK_0.2_ALL_log10p", "OutFLANK_0.2_PRUNED_log10p",
      "baypass_2.1_ALL_XTX", "baypass_2.1_PRUNED_XTX",
  ## Assoc methods
      "LFMM_ridge_0.0_ALL_log10p", "LFMM_lasso_0.0_ALL_log10p",
      "LEA_1.2.0_ALL_K3_log10p", "Spearmans_ALL_rho",
      "baypass_2.1_ALL_BF_env", "baypass_2.1_PRUNED_BF_env")

# This code loops through each statistic and each replicate simulation
# and creates a list - basically just putting things into format for analysis
perf_df <- data.frame(method=NULL, perf_SS=NULL, perf_QTN=NULL)
predict_list <- list()
for (j in 1:length(togetcols)){
  print(c(j, "of", length(togetcols)))
  for (i in 1:length(inver_simID)){
    #print(i)
  predict_list[[i]] <- as.numeric(unlist(x_all[x_all$simID==inver_simID[i], which(colnames(x_all)==togetcols[j])]))
  }
  #str(predict_list)
  
  # QTN performance
  manypred_QTN = prediction(predict_list, label_list_QTN)
  auc.perf_QTN = performance(manypred_QTN, measure = "auc")
  perf_QTN <- as.numeric(unlist(auc.perf_QTN@y.values))

  # SS performance
  # note that with only one prediction (sweep site), can't compute AUC
  manypred_SS = prediction(predict_list, label_list_SS)
  auc.perf_SS = performance(manypred_SS, measure = "auc")
  perf_SS <- as.numeric(unlist(auc.perf_SS@y.values))
  
  perf_df <- rbind(perf_df, data.frame(method=togetcols[j], perf_QTN=perf_QTN, perf_SS=perf_SS, simID = inver_simID))
}

## If adding new results, update the name of the variable here
## to be the name for plotting
perf_df2 <- perf_df %>%
     mutate(name = recode(method, 
      Hscan_v1.3_H12 = "H12", 
      rehh_2.0.2_ALL_log10p = "iHS", 
  ## DO methods             
      pcadapt_3.0.4_ALL_log10p = "PCAdapt Naive",
      pcadapt_3.0.4_PRUNED_log10p = "PCAdapt BP",
      OutFLANK_0.2_ALL_log10p = "OutFLANK Naive", 
      OutFLANK_0.2_PRUNED_log10p = "OutFLANK BP",
      baypass_2.1_ALL_XTX = "XTX Naive", 
      baypass_2.1_PRUNED_XTX = "XTX BP",
  ## Assoc methods
      LFMM_ridge_0.0_ALL_log10p = "LFMM ridge (pheno)", 
      LFMM_lasso_0.0_ALL_log10p = "LFMM lasso (pheno)",
      LEA_1.2.0_ALL_K3_log10p = "LEA (envi)", 
      Spearmans_ALL_rho = "Spearman's rho (envi)",
      baypass_2.1_ALL_BF_env = "BayPass (envi) Naive", 
      baypass_2.1_PRUNED_BF_env = "BayPass (envi) BP"
      ) # end recode
   )

## Determine color scheme. 
  # If adding new results, you may need to update the color scheme based on the information below:
    # For Only option, blank patterning. 
    # For Naive option, dot patterning.
    # For best practice, hashed patterning.
    ## SS methods - shades of purple
    ## DO methods - shades of orange and red
    ## Assoc methods - shades of blue and green
  # Map color onto perf_df
  # Map shading onto perf_df
plot_df <- data.frame(method=togetcols)
plot_df <- plot_df %>% mutate(color = recode(method,
      Hscan_v1.3_H12 = "#cfcdf5", # wind chime palette on color-hex.com
      rehh_2.0.2_ALL_log10p = "#9bc2f7", 
  ## DO methods             
      pcadapt_3.0.4_ALL_log10p = "#ecd292", # amber safety palette on color-hex.com
      pcadapt_3.0.4_PRUNED_log10p = "#ecd292",
      OutFLANK_0.2_ALL_log10p = "#e5a267", 
      OutFLANK_0.2_PRUNED_log10p = "#e5a267",
      baypass_2.1_ALL_XTX = "#d27254", 
      baypass_2.1_PRUNED_XTX = "#d27254",
  ## Assoc methods
      LFMM_ridge_0.0_ALL_log10p = "#2b9ddb", # Dark stormy sea on color-hex.com
      LFMM_lasso_0.0_ALL_log10p = "#394856",
      LEA_1.2.0_ALL_K3_log10p = "#7cfac3", 
      Spearmans_ALL_rho = "#00ab84",
      baypass_2.1_ALL_BF_env = "#9db69f", 
      baypass_2.1_PRUNED_BF_env = "#9db69f"
      )# end recode
) 

head(plot_df)

head(perf_df2)  

  ngroups<- length(togetcols)
  dval = c(0,0,10,0,10,0,10,0,0,0,0,0,10,0) # If adding new results, may need to edit this line. Naive approach should be hatched.
  aval=45
  
pdf("figures/AUC.pdf", width=6, height=10)
  par(mar=c(1, 1, 1,1), mfrow=c(2, 1), oma=c(10, 4,0,0))
  
  outstat <- boxplot(perf_df2$perf_SS~perf_df2$name, las=2, names=NA,
          main = "A) Global sweep", col=as.character(plot_df$color),
          ylim=c(0,1), density=20)
  abline(h=0.5)
  rect((1:ngroups)-.4, outstat$stats[2,], (1:ngroups)+.4, outstat$stats[4,],
       density=dval, angle=aval)
  
  outstat2 <- boxplot(perf_df2$perf_QTN~perf_df2$name, las=2, 
          main = "B) All QTNs",  ylim=c(0,1), col=as.character(plot_df$color))
  abline(h=0.5)
  rect((1:ngroups)-.4, outstat2$stats[2,], (1:ngroups)+.4, outstat2$stats[4,],
       density=dval, angle=aval)
  
  mtext("AUC", side=2, outer=TRUE, line=2, cex=1.5)
dev.off()
```



```{r}
library(data.table)
library(mltools)

perf_df2 <- perf_df2 %>% mutate(uniq=paste(method, simID, sep="_"))
head(perf_df2)
if(sum(duplicated(perf_df2$uniq))>0){print("Error in performance data frame"); break}

getQuant_region <- function(method, simid){
    bob <- x_all %>% filter(simID==simid) %>% 
          select(c("prop", method, "simID", "pos")) 
    P <- ecdf(unlist(bob[,method]))
    bob$cdf <-  P(unlist(bob[,method]))

    whichbob_LEQTL <- which(bob$prop==max(bob$prop, na.rm=TRUE))
    whichbob_Inversion <- which(bob$pos > 320000 & bob$pos < 330000)
    whichbob_SS <- which(bob$pos > (175001-2000) & bob$pos < (175001+2000))
    whichbob_lowR <- which(bob$pos > 370000 & bob$pos < 380000)
    whichbob_Rvar <- which(bob$pos > 400001 & bob$pos < 450000)
    whichbob_BS <- which((bob$pos > 220000 & bob$pos < 230000) | 
                     (bob$pos > 270000 & bob$pos < 280000))

  data.frame(uniq2=paste(method, simid,sep="_"),
             cdf_LEQTL=mean(bob$cdf[whichbob_LEQTL], na.rm=TRUE),
             cdf_Inversion = mean(bob$cdf[whichbob_Inversion], na.rm=TRUE),
             cdf_SS =mean(bob$cdf[whichbob_SS], na.rm=TRUE),
             cdf_lowR = mean(bob$cdf[whichbob_lowR], na.rm=TRUE),
             cdf_Rvar = mean(bob$cdf[whichbob_BS], na.rm=TRUE),
             cdf_BS = mean(bob$cdf[whichbob_BS], na.rm=TRUE)
             )
  # Take the average signal in the region, and count that for the replicate
}

### Quantiles
perf_df3 <- data.frame()
for (j in 1:nrow(perf_df2)){
  if(j%%50==0){print(c(j, "of", nrow(perf_df2)))}
  doa <- getQuant_region(as.character(perf_df2$method[j]), 
                         as.character(perf_df2$simID[j]))
  perf_df3 <- rbind(perf_df3, cbind(perf_df2[j,], doa))
}

head(perf_df3)

table(perf_df3$method, is.na(perf_df3$cdf_Inversion))



pdf("figures/Quantiles_lowR.pdf", width=6, height=10)
  par(mar=c(1, 1, 2,1), mfrow=c(2, 1), oma=c(10, 4,0,0))
  
  outstat <- boxplot(perf_df3$cdf_Inversion~perf_df3$name, las=2, names=NA,
          main = "A) Inversion (LG 7)", col=as.character(plot_df$color),
          ylim=c(0,1), density=20)
  abline(h=0.5)
  rect((1:ngroups)-.4, outstat$stats[2,], (1:ngroups)+.4, outstat$stats[4,],
       density=dval, angle=aval)
  
  outstat2 <- boxplot(perf_df3$cdf_lowR~perf_df3$name, las=2, 
          main = "B) Low recombination (r = 1e-08, LG 8)",  ylim=c(0,1), col=as.character(plot_df$color))
  abline(h=0.5)
  rect((1:ngroups)-.4, outstat2$stats[2,], (1:ngroups)+.4, outstat2$stats[4,],
       density=dval, angle=aval)
  
  
  mtext("Mean quantile", side=2, outer=TRUE, line=2, cex=1.5)
dev.off()




pdf("figures/Quantiles_other.pdf", width=6, height=10)
  par(mar=c(1, 1, 2,1), mfrow=c(3, 1), oma=c(10, 4,0,0))
  
  outstat <- boxplot(perf_df3$cdf_SS~perf_df3$name, las=2, names=NA,
          main = "A) Global sweep (LG 1)", col=as.character(plot_df$color),
          ylim=c(0,1), density=20)
  abline(h=0.5)
  rect((1:ngroups)-.4, outstat$stats[2,], (1:ngroups)+.4, outstat$stats[4,],
       density=dval, angle=aval)
  
  outstat2 <- boxplot(perf_df3$cdf_LEQTL~perf_df3$name, las=2, 
          main = "B) Largest effect QTN",  ylim=c(0,1), col=as.character(plot_df$color),
          names=NA)
  abline(h=0.5)
  rect((1:ngroups)-.4, outstat2$stats[2,], (1:ngroups)+.4, outstat2$stats[4,],
       density=dval, angle=aval)
  
  outstat2 <- boxplot(perf_df3$cdf_BS~perf_df3$name, las=2, 
          main = "C) Background selection (LG 5 and 6)",  ylim=c(0,1), col=as.character(plot_df$color))
  abline(h=0.5)
  rect((1:ngroups)-.4, outstat2$stats[2,], (1:ngroups)+.4, outstat2$stats[4,],
       density=dval, angle=aval)
  
  mtext("Mean quantile", side=2, outer=TRUE, line=2, cex=1.5)
dev.off()
```

```{r}

# Quantify outliers in recombination variation region based on P-value
-log10(0.05/7000)
# Bonferroni significant if -log10(P) > 5
# Or BF > 2
x_rv <- (x_all %>% filter(pos  > 400001 & pos < 450000) )
mean(table(x_rv$simID))
  # about 700 sites in this region

togetcols

# Calculate proportion of sites that are outliers in R-var region
Rvar_Pval <- function(method){
  yo1 <- x_rv %>% select(method, simID)
  tapply(unlist(yo1[,method]), yo1$simID, function(x){sum(x>5, na.rm=TRUE)/sum(!is.na(x))})
}

mean(Rvar_Pval("pcadapt_3.0.4_ALL_log10p"))
mean(Rvar_Pval("pcadapt_3.0.4_PRUNED_log10p"))


Rvar_BF <- function(method){
  yo1 <- x_rv %>% select(method, simID)
  tapply(unlist(yo1[,method]), yo1$simID, function(x){sum(x>2, na.rm=TRUE)/sum(!is.na(x))})
}
mean(Rvar_BF("baypass_2.1_ALL_BF_env"))
mean(Rvar_BF("baypass_2.1_PRUNED_BF_env"))
0.003*700

Rvar_quant <- function(method){
  yo1 <- x_rv %>% select(method, simID)
  q <- x_all %>% select(method) %>% unlist %>% quantile(0.95, na.rm=TRUE)
  tapply(unlist(yo1[,method]), yo1$simID, function(x){sum(x>q, na.rm=TRUE)/sum(!is.na(x))})
}
summary(Rvar_quant("Hscan_v1.3_H12"))


# Quantify BF for inversion region
x_inv <- (x_all %>% filter(pos  > 320000 & pos < 330000) )
Inv_BF <- function(method){
  yo1 <- x_inv %>% select(method, simID)
  tapply(unlist(yo1[,method]), yo1$simID, mean)
}
mean(Inv_BF("baypass_2.1_ALL_BF_env"))
mean(Inv_BF("baypass_2.1_PRUNED_BF_env"))
quantile(unlist(x_all[,"baypass_2.1_ALL_BF_env"]), c(0.5,0.6), na.rm=TRUE)

```