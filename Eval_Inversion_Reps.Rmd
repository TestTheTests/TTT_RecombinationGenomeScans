---
title: "Eval_Inversion_Reps"
author: "Katie Lotterhos"
date: "3/13/2018"
output: html_document
---
First, remember to set your working directory:

setwd("/Users/katie/Desktop/Repos/TestTheTests/TTT_RecombinationGenomeScans")

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# !diagnostics off

if(!("tidyverse" %in% installed.packages())){install.packages("tidyverse")}
library(tidyverse)
if(!("RSQLite" %in% installed.packages())){install.packages("RSQLite")}
library(RSQLite)
if(!("dbplyr" %in% installed.packages())){install.packages("dbplyr")}
library(dbplyr)
if(!("ROCR" %in% installed.packages())){install.packages("ROCR")}
library(ROCR)
if(!("vcfR" %in% installed.packages())){install.packages("vcfR")}
library(vcfR)
if(!("data.table" %in% installed.packages())){install.packages("data.table")}
library(data.table)
if(!("PRROC" %in% installed.packages())){install.packages("PRROC")}
library(PRROC)

    library(RColorBrewer)
    library(fields)

options(readr.show_progress=FALSE)
```

This markdown is structured so that new results can be easily added. Just look for the keywords "To add new results."

Your working directory should be set to "TTT_RecombinationGenomeScans"

Your new results table should have column headings `program_version_SNPset_statistic`

* For example, to if you ran the program OutFLANK v 0.2 and calculated FST, then your column name would be `OutFLANK_0.2_FST`. If you then calculated -log10 P-values for each locus using ALL the SNPs in the data to calculate the null parameters on the neutral distribution of FST, then your column name would be `OutFLANK_0.2_ALL_log10p`. If you had instead calculated -log10 P-values for each locus using ONLY A PRUNED SET of SNPs (e.g., thinned for linkage disequilibrium as described in the paper) to calculate the null parameters on the neutral distribution of FST, then your column name would be `OutFLANK_0.2_PRUNED_log10p`.

* The pruned set of quasi-independent SNPs are indicated in the column `quasi_indep`

Some things to understand about the structure of the files: 

The "Invers_ScanResults" files have all the loci in the .vcf file, as well as all causal mutations (some of which were filtered before they were put into the vcf file). 

* The column in this dataframe called `keep_loci` indicates whether the loci was in the vcf file. 
* The column called `unique` is a unique identifier for each locus. This identifier is recommended to be used for any programs that will take a locus name, as it will ensure that the dataframes are correctly merged.

The LEA and Baypass results give output in the same order as the loci in the vcf file. If you program output results in a different order, than you should be sure to re-order them for the code to work.

# Read in files

This chunk of code inputs the results files. Each time an additional program is run, a new set of output files are generated. Those files can be added to the pipeline below and merged with the existing files, then easily incoporated into the subsequent analyses.

BF log10(BF)
eBPis log10 P value

```{r}
 
inver_files = list.files("results_final", pattern = "Invers_ScanResults")
inver_files
inver_simID <- substr(inver_files, 1, 5)
inver_simID
length(inver_simID)

scikit_files = list.files("results_final", pattern = "scikitallel.txt")
LEA_files = paste0(inver_simID, "_Invers_LEA.txt")
Baypass_files = paste0(inver_simID, "_baypass_results.txt")
# To add new results, add a line of code here to get a list of the files

if (!((length(inver_files)==length(scikit_files)) | 
      (length(inver_files)==length(LEA_files)) |
      (length(inver_files)==length(Baypass_files)) 
      )){
  print("Error: number of files not equal")
  break
}

# To add new results, add a line of code here to check that the number of files is the same as the number of simulations


x_all <- NULL
for (i in 1:length(inver_files)){
  print(inver_simID[i])
  ## Main results
  x1 <- read_delim(paste0("results_final/", inver_files[i]), delim=" ")
  x1$type = "Inversion"
  x1 <- x1[order(x1$vcf_ord),]
    # It's important to order results here in same order as vcf file
    # because most other programs are outputting results in that order
  
  # ## scikit results
   x1_ska <- read_delim(paste0("results_final/", scikit_files[i]), delim=" ")
   if (sum(x1$keep_loci, na.rm=TRUE)!=nrow(x1_ska)){
     print("Error: wrong number of loci in scikit file"
     )
   }
  x1_ska$unique <- x1$unique[which(x1$keep_loci)]
  names(x1_ska) <- gsub("sk-a","ska", names(x1_ska))
  names(x1_ska) <- gsub("H2/H1","H2H1", names(x1_ska))
  names(x1_ska)
  # 
  
  # ## LEA results
   x1_LEA <- read_delim(paste0("results_final/", LEA_files[i]), delim=" ")
   if (sum(x1$keep_loci, na.rm=TRUE)!=nrow(x1_LEA)){
     print("Error: wrong number of loci in LEA file"
     )
   }
   x1_LEA$unique <- x1$unique[which(x1$keep_loci)]
  # 
   ## BayPass results
   #x1_baypass <- read.table(paste0("results_final/", Baypass_files[i]), header=TRUE)
   x1_baypass <- read_delim(paste0("results_final/", Baypass_files[i]), delim=" ")
     if (sum(x1$keep_loci, na.rm=TRUE)!=nrow(x1_baypass)){
     print("Error: wrong number of loci in baypass file"
     )
   }
   x1_baypass$unique <- x1$unique[which(x1$keep_loci)]
  # 

  
  ### New Results
  ### To add new results, copy and paste this code (leave this example for others), and rename it using the same structure as above
  ### Make sure you choose the appropriate delimiter
  ### x1_new <- read_delim(paste0("results_final/", my_files[i]), delim=" ")
  ###  if (sum(x1$keep_loci)!=nrow(x1_new)){
  ###  print("Error: wrong number of loci in new file"
  ###  )
  ### }
  ### x1_new$unique <- x1$unique[which(x1$keep_loci)]
  
  ## Combine all tables
   x_final0 <- left_join(x1, x1_ska, by="unique")
   x_final1 <- left_join(x_final0, x1_LEA, by="unique")
   x_final2 <- left_join(x_final1, x1_baypass, by="unique")
  
  x_final <- x_final2
  
  ### To add new results, reword this code and write a new example for others
  ### x_final4 <- left_join(x_final3, x1_new, by="unique")
  ### x_final <- x_final4
  ### rm(x_final1, x_final2, x_final4)
  
  if(nrow(x_final)!=nrow(x1)){
    print("Error in merging files, number of rows has changed")
  }
  x_all <- rbind(x_all, x_final)
  #rm(x_final, x_final1, x_final2, x_final3)
  # If adding new results, be sure to remove above
}

table(x_all$simID)

#Number of simulations
nlevels(factor(x_all$simID))

names(x_all)[2] <- "pos"

x_all
x_all <- as.data.frame(x_all)
x_all <- tbl_df(x_all)
  # number of rows should be XXXXX
#if(nrow(x_all) != XXXXX){
#  print("Error in data upload"); break;
#}
```


## Set up genetic map for figures
No need to edit any of this code if you are adding a new method
```{r}

### Color recombination regions ####
  lgs <- seq(50000, 450000, by=50000) # linkage groups recombination breakpoints 0.5
  lg_whereplot <- lgs - 25000
  r <- 1e-05
  r_low <- 1e-11
  r_med <- 1e-08
  r_var = 10^(-1*(rnorm(1000, mean=5, sd=2)))
  quantile(log10(r_var), probs = c(0.1, 0.9))
  
  # each chrom 50000 bp long
  # chrom 1 neutral r
  # chrom 2 QTL r
  # chrom 3 QTL r
  # chrom 4 sweep r
  # chrom 5, 6 background r
  # chrom 7 had inversion 320000-330000
  # chrom 8 had r_med 370000-380000
  # chrom 9 had recombination variation
  # chrom 10 neutral r
  
### Plot function

plot_layers <- function(y_head=0, y_arrows=c(1,0.25), thisSim=NULL, ...){

  # Inversion
  polygon(x=c(320000, 330000, 330000, 320000),
          y = c(-10000, -10000, 100000, 100000),
          col=rgb(1,0,0,0.3), border=NA)
  
  
  abline(v=lgs, col=adjustcolor("grey", 0.5))
  
   # Low Recomb region
  polygon(x=c(370000, 380000, 380000, 370000),
          y = c(-10000, -10000, 100000, 100000),
          col=rgb(0,0,1,0.3), border=NA)
 
  
  polygon(x=c(400000, 450000, 450000, 400000),
          y = c(-10000, -10000, 100000, 100000),
          col=rgb(0,0,1,0.1), border=NA)
  
  text(lg_whereplot, y = y_head, 
       labels = c("LG1\nNeut", "LG2\nNeut", "LG3\nQTL",
                  "LG4\nQTL", "LG5\nFull\nsweep",
                  "LG6\nPartial\nsweep", "LG7\nNeut\nInversion",
                  "LG8\n r=1e-08", "LG9\nr var"))
  
  
  ### Add QTLs and Sweep Location
  if(length(thisSim)>0){
  muts <- x_all %>% filter(simID==thisSim)
  arrows(muts$pos[muts$descrip=="QTL"],  y_arrows[1], muts$pos[muts$descrip=="QTL"],  y_arrows[2], col="orange", lwd=muts$prop[muts$descrip=="QTL"]*10, length = 0.1)
  }
  
  arrows(225000, y_arrows[1], 225000, y_arrows[2], col="purple", lwd=2, length = 0.1)
  arrows(275000, y_arrows[1], 275000, y_arrows[2], col="purple", lwd=2, length = 0.1)
} #end plot function

pdf("figures/InversionMap.pdf", width=12, height=4)
  par(mar=c(4,2,1,2))
  plot(0,0, col="white", xlim=c(0, 450000), ylim=c(-1,1), xaxs="i", yaxt="n", ylab="", xlab="Position (bp)")
  plot_layers()
dev.off()  
```


## Proportion of loci in inversion
```{r inversion}
## Inversion
xin <- x_all[x_all$pos > 320000 & x_all$pos < 330000,]
summary(tapply(xin$pos,xin$simID, length)/tapply(x_all$pos,x_all$simID, length))

## Low Recombination region
xin <- x_all[x_all$pos > 370000 & x_all$pos < 380000,]
summary(tapply(xin$pos,xin$simID, length)/tapply(x_all$pos,x_all$simID, length))
```

## Effect size and allele frequency
No need to edit this code if you are adding a new method
```{r effect size a_freq}

head(x_all)
levels(factor(x_all$simID))
nlevels(factor(x_all$simID))
sum(is.na(x_all$simID))
  
  mean(tapply(x_all$simID, x_all$simID, length)) # ave number of SNPs after filtering
  
    mean(tapply(x_all$prop>=0.01, x_all$simID, sum, na.rm=TRUE)) # ave number of causal common SNPs after filtering
    
    # check that AGV sums to 1 for all simulations
    tapply(x_all$prop, x_all$simID, sum, na.rm=TRUE)
      # all mutations here
    
    mean(tapply(x_all$prop, x_all$simID, max, na.rm=TRUE)) # ave effect size of max SNP
    
    #x <- x_all[which(x_all$simID==10903 & x_all$muttype=="MT=2"),]#& x_all$keep_loci==FALSE & x_all$count==TRUE),]
  
  # check no NA's for allele frequency
  sum(is.na(x_all$a_freq_final))
  
  # check NAs for simulated loci that were filtered for analysis  (should all have MAF < 0.01)
  print.data.frame(x_all[is.na(x_all$keep_loci),c("pos","a_freq_old", "descrip", "originGen", "seed")])
  
  x_all$keep_loci[which(is.na(x_all$keep_loci))] <- FALSE
    # These are NA in the data
  
  countbutnotinfinal <- which(x_all$keep_loci==FALSE & x_all$prop>=0.01 & x_all$descrip=="QTL") # rare alleles of large effect
  keepcount <- which(x_all$keep_loci==TRUE & x_all$prop>=0.01 & x_all$descrip=="QTL")  # common alleles of large effect
  dontkeepdontcount <- which(x_all$keep_loci==FALSE & x_all$prop<0.01 & x_all$descrip=="QTL") # rare alleles small effect
  keepdontcount <- which(x_all$keep_loci==TRUE & x_all$prop<0.01 & x_all$descrip=="QTL")
    # common alleles of small effect
  
  levels(factor(x_all$descrip))
  #sanity check: these should be equal
    sum(x_all$descrip=="QTL", na.rm=TRUE) # number of M2 mutations
    length(c( countbutnotinfinal, keepcount, dontkeepdontcount, keepdontcount))
    # these should be equal

  length(countbutnotinfinal)
    # $keep_loci means they were not in the final vcf file

  mean(x_all$prop[countbutnotinfinal], na.rm=TRUE)
```

```{r make effect size plot}
pdf("figures/PlotFreqVsEffectSize.pdf", width=7, height=9)
  par(mfrow=c(2,1), mar=c(3,3,1,1), oma=c(3,3,0,0))
  
    # common causal alleles
    plot(x_all$a_freq_final[keepcount], abs(x_all$selCoef[keepcount]), col=adjustcolor("#F0AE2D", 0.5), pch=19, ylim=c(0,3.2), ylab="", xlab="")

    # rare causal alleles of smaller effect
    points(x_all$a_freq_final[dontkeepdontcount], abs(x_all$selCoef[dontkeepdontcount]), pch=2, col=adjustcolor("#0067E5", 0.5))
    
    # common causal alleles of smaller effect
    points(x_all$a_freq_final[keepdontcount], abs(x_all$selCoef[keepdontcount]), pch=1, col=adjustcolor("#00397F", 0.5))
    
    # rare causal alleles of larger effect
    points(x_all$a_freq_final[countbutnotinfinal], abs(x_all$selCoef[countbutnotinfinal]), pch=17, col=adjustcolor("#B27600", 0.5))
  
  # zoom in on x-axis
      legend(0.3,3, c("Common alleles > 1% AGV", "Common alleles < 1% AGV", "Rare alleles > 1% AGV", "Rare alleles < 1% AGV"), pch=c(19,1, 17, 2), col=c("#F0AE2D", "#00397F", "#B27600", "#0067E5"),bty="n")
      
    plot(x_all$a_freq_final[keepcount], abs(x_all$selCoef[keepcount]), col=adjustcolor("#F0AE2D", 0.5), pch=19, ylim=c(0,3.2), ylab="", xlab="", xlim=c(0,0.02))
    points(x_all$a_freq_final[dontkeepdontcount], abs(x_all$selCoef[dontkeepdontcount]), pch=2, col=adjustcolor("#0067E5", 0.5))
    points(x_all$a_freq_final[keepdontcount], abs(x_all$selCoef[keepdontcount]), pch=1, col=adjustcolor("#00397F", 0.5))
    points(x_all$a_freq_final[countbutnotinfinal], abs(x_all$selCoef[countbutnotinfinal]), pch=17, col=adjustcolor("#B27600", 0.5))
    abline(v = 0.01, col="grey")
    text(0.075,3.1, "Zoom in on x-axis")
    mtext("Frequency", 1, outer=TRUE)
    mtext("Effect Size", 2, outer=TRUE)
  dev.off()
```

```{r AGV}
# For each simulation, let's see how much genetic variance remains unexplained by causal loci that are not in the final dataset, but contribute more than 1% to AGV
    # these are rare loci of large effect
  (totAGV_rareLarge <- 
   tapply(x_all$prop[countbutnotinfinal], x_all$simID[countbutnotinfinal], sum, na.rm=TRUE))
   (totAGV_rareLargenum <- tapply(x_all$prop[countbutnotinfinal], x_all$simID[countbutnotinfinal], length)) # note this doesn't include 0s
  
  quantile(totAGV_rareLarge, c(0.025,0.5, 0.975))
  mean(totAGV_rareLarge)
  # on average 4.5% of genetic variance remains unexplained by causal loci not in the final dataset
  
# For each simulation, let's see how much genetic variance remains unexplained by causal loci that are not in the final dataset, and contribute LESS than 1% to AGV
  # rare alleles of small effect
  (totAGV_rareSmall <-   tapply(x_all$prop[dontkeepdontcount], x_all$simID[dontkeepdontcount], sum, na.rm=TRUE))
   (totAGV_rareSmallNum <-   tapply(x_all$prop[dontkeepdontcount], x_all$simID[dontkeepdontcount], length))
  
    (totAGV_commonSmall <-   tapply(x_all$prop[keepdontcount], x_all$simID[keepdontcount], sum, na.rm=TRUE))
  (totAGV_commonSmallNum <-   tapply(x_all$prop[keepdontcount], x_all$simID[keepdontcount], length))
  
# For each simulation, let's see how much genetic variance is explained by common alleles that are in the dataset
  (totAGV_common <-   tapply(x_all$prop[keepcount], x_all$simID[keepcount], sum, na.rm=TRUE))
   (totAGV_commonNum <-   tapply(x_all$prop[keepcount], x_all$simID[keepcount], length))
  

  totAGV <- data.frame(simID=names(totAGV_common), totAGV_common, totAGV_commonNum, totAGV_rareSmall, totAGV_rareSmallNum) %>% merge( data.frame(simID=names(totAGV_rareLarge), totAGV_rareLarge, totAGV_rareLargenum), all.x=TRUE) %>% merge( data.frame(simID=names(totAGV_commonSmall), totAGV_commonSmall, totAGV_commonSmallNum), all.x=TRUE) 
  totAGV$sum <- rowSums(totAGV[,c(2,4,6,8)], na.rm=TRUE)  
  totAGV[is.na(totAGV)] <- 0
  apply(totAGV[,2:10], 2, quantile, c(0.05, 0.5, 0.95, 1.0))
  totAGV
```

```{r proportion AGV across sims}   
# Make a plot of histograms
  pdf("figures/PropAGVacrossSims.pdf", width=5, height = 4)
  #par(mfrow=c(3,1))
  #hist(totAGV_rareSmall, breaks=seq(0,1,0.05))
  #hist(totAGV_rareLarge, breaks=seq(0,1,0.05))
  #hist(totAGV_common, breaks=seq(0,1,0.05)) 
    par(mfrow=c(1,1), mar=c(5,4,1,1), oma=c(1,0,0,0))
    barplot(rbind(totAGV$totAGV_common[1:30], totAGV$totAGV_rareLarge[1:30], 
                  totAGV$totAGV_commonSmall[1:30], totAGV$totAGV_rareSmall[1:30]), 
                  col=c("#F0AE2D","#B27600" , "#00397F", "#0067E5"),  
                  ylab="Proportion of additive genetic variance", 
                  names.arg = rep("", 30))
    mtext("Simulation replicate", 1)
    par(fig = c(0, 1, 0, 1), oma = c(0, 1, 0, 1), mar = c(3, 4, 1, 4), new = TRUE)
    plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n", ylab="", xlab="")
    legend("bottom", c("Common alleles", "Rare alleles\nlarge effect", "Common alleles\nsmall effect", "Rare alleles\nsmall effect"), xpd = TRUE, horiz = TRUE, inset = c(0, 0), bty = "n",  fill= c("#F0AE2D","#B27600" , "#00397F", "#0067E5"), cex =0.7, border="black")
  dev.off()
```

### Multiplot function
copied from cookbook for R. 

No need to edit this code if you are adding a new method.
```{r}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}



shaded.bxp <- function (z, notch = FALSE, width = NULL, varwidth = FALSE, outline = TRUE, 
    notch.frac = 0.5, log = "", border = par("fg"), pars = NULL, 
    frame.plot = axes, horizontal = FALSE, add = FALSE, at = NULL, 
    show.names = NULL, density=NULL, angle=45,  ...) 
{ 
    pars <- c(list(...), pars) 
    pars <- pars[unique(names(pars))] 
    bplt <- function(x, wid, stats, out, conf, notch, xlog, i, density, angle=45, boxfill) { 
        ok <- TRUE 
        if (!any(is.na(stats))) { 
            xP <- if (xlog) 
                function(x, w) x * exp(w) 
            else function(x, w) x + w 
            wid <- wid/2 
            if (notch) { 
                ok <- stats[2L] <= conf[1L] && conf[2L] <= stats[4L] 
                xx <- xP(x, wid * c(-1, 1, 1, notch.frac, 1, 
                  1, -1, -1, -notch.frac, -1)) 
                yy <- c(stats[c(2, 2)], conf[1L], stats[3L], 
                  conf[2L], stats[c(4, 4)], conf[2L], stats[3L], 
                  conf[1L]) 
            } 
            else { 
                xx <- xP(x, wid * c(-1, 1, 1, -1)) 
                yy <- stats[c(2, 2, 4, 4)] 
            } 
            if (!notch) 
                notch.frac <- 1 
            wntch <- notch.frac * wid 
            xypolygon(xx, yy, lty = "blank", col = boxfill[i], density=density[i], angle=angle[i]) 
            xysegments(xP(x, -wntch), stats[3L], xP(x, +wntch), 
                stats[3L], lty = medlty[i], lwd = medlwd[i], 
                col = medcol[i], lend = 1) 
            xypoints(x, stats[3L], pch = medpch[i], cex = medcex[i], 
                col = medcol[i], bg = medbg[i]) 
            xysegments(rep.int(x, 2), stats[c(1, 5)], rep.int(x, 
                2), stats[c(2, 4)], lty = whisklty[i], lwd = whisklwd[i], 
                col = whiskcol[i]) 
            xysegments(rep.int(xP(x, -wid * staplewex[i]), 2), 
                stats[c(1, 5)], rep.int(xP(x, +wid * staplewex[i]), 
                  2), stats[c(1, 5)], lty = staplelty[i], lwd = staplelwd[i], 
                col = staplecol[i]) 
            xypolygon(xx, yy, lty = boxlty[i], lwd = boxlwd[i], 
                border = boxcol[i], density=density[i], angle=angle[i], col=boxfill[i]) 
            if ((nout <- length(out))) { 
                xysegments(rep(x - wid * outwex, nout), out, 
                  rep(x + wid * outwex, nout), out, lty = outlty[i], 
                  lwd = outlwd[i], col = outcol[i]) 
                xypoints(rep.int(x, nout), out, pch = outpch[i], 
                  lwd = outlwd[i], cex = outcex[i], col = outcol[i], 
                  bg = outbg[i]) 
            } 
            if (any(inf <- !is.finite(out))) { 
                warning(sprintf(ngettext(length(unique(out[inf])), 
                  "Outlier (%s) in boxplot %d is not drawn", 
                  "Outliers (%s) in boxplot %d are not drawn"), 
                  paste(unique(out[inf]), collapse = ", "), x), 
                  domain = NA) 
            } 
        } 
        return(ok) 
    } 
    if (!is.list(z) || 0L == (n <- length(z$n))) 
        stop("invalid first argument") 
    if (is.null(at)) 
        at <- 1L:n 
    else if (length(at) != n) 
        stop("'at' must have same length as 'z$n', i.e. ", n) 
    if (is.null(z$out)) 
        z$out <- numeric() 
    if (is.null(z$group) || !outline) 
        z$group <- integer() 
    if (is.null(pars$ylim)) 
        ylim <- range(z$stats[is.finite(z$stats)], if (outline) z$out[is.finite(z$out)], 
            if (notch) z$conf[is.finite(z$conf)]) 
    else { 
        ylim <- pars$ylim 
        pars$ylim <- NULL 
    } 
    if (is.null(pars$xlim)) 
        xlim <- c(0.5, n + 0.5) 
    else { 
        xlim <- pars$xlim 
        pars$xlim <- NULL 
    } 
    if (length(border) == 0L) 
        border <- par("fg") 
    dev.hold() 
    on.exit(dev.flush()) 
    if (!add) { 
        plot.new() 
        if (horizontal) 
            plot.window(ylim = xlim, xlim = ylim, log = log, 
                xaxs = pars$yaxs) 
        else plot.window(xlim = xlim, ylim = ylim, log = log, 
            yaxs = pars$yaxs) 
    } 
    xlog <- (par("ylog") && horizontal) || (par("xlog") && !horizontal) 
    pcycle <- function(p, def1, def2 = NULL) rep(if (length(p)) p else if (length(def1)) def1 else def2, 
        length.out = n) 
    p <- function(sym) pars[[sym, exact = TRUE]] 
    boxlty <- pcycle(pars$boxlty, p("lty"), par("lty")) 
    boxlwd <- pcycle(pars$boxlwd, p("lwd"), par("lwd")) 
    boxcol <- pcycle(pars$boxcol, border) 
    boxfill <- pcycle(pars$boxfill, par("bg")) 
    density <- rep(density, length.out=n) 
    density <- rep(density, length.out=n) 
    angle <- rep(angle, length.out=n) 
    boxwex <- pcycle(pars$boxwex, 0.8 * { 
        if (n <= 1) 
            1 
        else stats::quantile(diff(sort(if (xlog) 
            log(at) 
        else at)), 0.1) 
    }) 
    medlty <- pcycle(pars$medlty, p("lty"), par("lty")) 
    medlwd <- pcycle(pars$medlwd, 3 * p("lwd"), 3 * par("lwd")) 
    medpch <- pcycle(pars$medpch, NA_integer_) 
    medcex <- pcycle(pars$medcex, p("cex"), par("cex")) 
    medcol <- pcycle(pars$medcol, border) 
    medbg <- pcycle(pars$medbg, p("bg"), par("bg")) 
    whisklty <- pcycle(pars$whisklty, p("lty"), "dashed") 
    whisklwd <- pcycle(pars$whisklwd, p("lwd"), par("lwd")) 
    whiskcol <- pcycle(pars$whiskcol, border) 
    staplelty <- pcycle(pars$staplelty, p("lty"), par("lty")) 
    staplelwd <- pcycle(pars$staplelwd, p("lwd"), par("lwd")) 
    staplecol <- pcycle(pars$staplecol, border) 
    staplewex <- pcycle(pars$staplewex, 0.5) 
    outlty <- pcycle(pars$outlty, "blank") 
    outlwd <- pcycle(pars$outlwd, p("lwd"), par("lwd")) 
    outpch <- pcycle(pars$outpch, p("pch"), par("pch")) 
    outcex <- pcycle(pars$outcex, p("cex"), par("cex")) 
    outcol <- pcycle(pars$outcol, border) 
    outbg <- pcycle(pars$outbg, p("bg"), par("bg")) 
    outwex <- pcycle(pars$outwex, 0.5) 
    width <- if (!is.null(width)) { 
        if (length(width) != n | any(is.na(width)) | any(width <= 
            0)) 
            stop("invalid boxplot widths") 
        boxwex * width/max(width) 
    } 
    else if (varwidth) 
        boxwex * sqrt(z$n/max(z$n)) 
    else if (n == 1) 
        0.5 * boxwex 
    else rep.int(boxwex, n) 
    if (horizontal) { 
        xypoints <- function(x, y, ...) points(y, x, ...) 
        xypolygon <- function(x, y, ...) polygon(y, x, ...) 
        xysegments <- function(x0, y0, x1, y1, ...) segments(y0, 
            x0, y1, x1, ...) 
    } 
    else { 
        xypoints <- points 
        xypolygon <- polygon 
        xysegments <- segments 
    } 
    ok <- TRUE 
    for (i in 1L:n) ok <- ok & bplt(at[i], wid = width[i], stats = z$stats[, 
        i], out = z$out[z$group == i], conf = z$conf[, i], notch = notch, 
        xlog = xlog, i = i, density=density, angle=angle, boxfill=boxfill) 
    if (!ok) 
        warning("some notches went outside hinges ('box'): maybe set notch=FALSE") 
    axes <- is.null(pars$axes) 
    if (!axes) { 
        axes <- pars$axes 
        pars$axes <- NULL 
    } 
    if (axes) { 
        ax.pars <- pars[names(pars) %in% c("xaxt", "yaxt", "xaxp", 
            "yaxp", "las", "cex.axis", "col.axis", "format")] 
        if (is.null(show.names)) 
            show.names <- n > 1 
        if (show.names) 
            do.call("axis", c(list(side = 1 + horizontal, at = at, 
                labels = z$names), ax.pars)) 
        do.call("Axis", c(list(x = z$stats, side = 2 - horizontal), 
            ax.pars)) 
    } 
    do.call("title", pars[names(pars) %in% c("main", "cex.main", 
        "col.main", "sub", "cex.sub", "col.sub", "xlab", "ylab", 
        "cex.lab", "col.lab")]) 
    if (frame.plot) 
        box() 
    invisible(at) 
} 
```

### Inversion stats
```{r inversion hist of MAF and origin gen}
bob <- as.numeric(unlist(x_all %>% filter(descrip=="Inversion")  %>% select(a_freq_final)))

bob_MAF<- bob
bob_MAF[which(bob>0.5)] <- 1- bob[which(bob>0.5)]

origin <- as.numeric(unlist(x_all %>% filter(descrip=="Inversion") %>% select(originGen)))

pdf("figures/InversionMAF_hist.pdf", width=5, height=8)
  par(mar=c(4,4, 1,0.5), mfrow=c(2,1), oma=c(0,0,0,0))
  hist(bob, xlim=c(0,1.0), main=NULL, breaks=seq(0,1, by=0.05), xlab="Haplotype frequency at inversion", ylab="Number of simulations")

  hist(origin, main="", xlab="Generation of origin of the inversion")
dev.off()

inv_data = data.frame(inver_simID, af=bob, MAF=bob_MAF, origin)
inv_data[order(inv_data$MAF),]
```
 

### Evaluate population structure
 No need to edit this code if you are adding a new method
 
```{r inversion PC loadings this sim}

thisim = 10913 #10903

x_all %>% filter(seed==thisim, descrip=="Inversion")  %>% select(a_freq_final, originGen)

forpdf <- x_all[x_all$simID==thisim,]

(inv_loc <- forpdf$pos[which(forpdf$descrip=="Inversion")]) # this gives position within inversion

### PC loadings of loci ####
par(mar=c(4,4,1,1))
plot(forpdf$pos, forpdf$pca_ALL_PC1_loadings,
     ylim=c(-0.2, 0.2),
      pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "PC1 loadings", xaxt="n")#, 
     #xlim=c(170000 , 180000))
  plot_layers(y_head=10, y_arrows=c(10000, 8000), thisSim = thisim)
  plot(forpdf$pos, forpdf$pca_ALL_PC2_loadings,
     ylim=c(-0.2, 0.2),
      pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "PC1 loadings", xaxt="n")#, 
     #xlim=c(170000 , 180000))
  plot_layers(y_head=10, y_arrows=c(10000, 8000), thisSim = thisim)
  
  plot(forpdf$pos, forpdf$pca_PRUNED_PC1_loadings,
     ylim=c(-0.2, 0.2),
      pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "PC1 loadings", xaxt="n")#, 
     #xlim=c(170000 , 180000))
  plot_layers(y_head=10, y_arrows=c(0.17,0.15), thisSim = thisim)
  plot(forpdf$pos, forpdf$pca_PRUNED_PC2_loadings,
     ylim=c(-0.2, 0.2),xlim=c(0,4.5e05),
      pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
     cex=0.5, ylab= "PC1 loadings", xaxt="n")#, 
     #xlim=c(170000 , 180000))
  plot_layers(y_head=10, y_arrows=c(10, 8), thisSim = thisim)

### PC scores of individuals ####
  # load individual data
  inddf <- read_delim(paste0("results_final/",
                             thisim,"_Invers_indFILT.txt"),
                      delim=" ")
  head(inddf)
  ind_geno <- read.vcfR(paste0("results_final/",
                             thisim, "_Invers_VCFallFILT.vcf.gz", sep=""))
  (inv_index2 <- grep(inv_loc, ind_geno@fix[,"POS"]))
    #32001-32999 is the location of the inversion
  
  genoinv <- (ind_geno@gt[inv_index2,-1])
  # check dimensions
    dim(inddf[which(inddf$infinal),])
    length(genoinv)
    genoinv[which(genoinv=="1|0")] <- "0|1" # set heterozygotes equal
    levels(factor(genoinv))

    myColors <- c("#2ca25f", "#9ebcda", "#8856a7")
    names(myColors) <- levels(factor(genoinv))
    colScale <- scale_colour_manual(name = "Inversion\ngenotype",values = myColors)
```

```{r plot PC scores}
pdf("figures/PC_scores_compare.pdf", width=6, height=9)    
 
  # Individual scores without LD pruning
  p1 <- qplot(inddf$pca_ALL_PC1_scores[inddf$infinal], inddf$pca_ALL_PC2_scores[inddf$infinal],
        colour=genoinv, 
        main="A) Individual scores (all SNPs)") + 
    colScale + theme_bw() + xlab("PC1 score") + ylab("PC2 score")

  # Individual scores with LD pruning
  p2<- qplot(inddf$pca_PRUNED_PC1_scores, inddf$pca_PRUNED_PC2_scores,
        colour=inddf$envi, main="B) Individual scores (thinned SNPs)", xlab="PC1 score", ylab="PC2 score" ) + theme_bw() + labs(colour="Environm.") + scale_color_gradient2( low="blue", mid="white", high="red", space ="Lab" )
  
  multiplot(p1, p2, cols=1)
  dev.off()
```

```{r}  
  ### which locations load onto PC all data ####
pdf("figures/WhichLocationsPCs.pdf", width=9, height=6)  
  PCA_lim <- 0.05

  par(mar=c(4, 4,1,1), oma=c(0,2,0,0), mfrow=c(3,1))
  d <- density(x_all$pos[which(abs(x_all$pca_ALL_PC1_loadings)>PCA_lim )], bw = 1000)
  plot(d, main="A) Locations of outlier PC1 loadings (all SNPs)", bty="l", las=1, ylim=c(0, 13e-05), xlim=c(0,4.5e05),adj=0,
       ylab="", xlab="")
  polygon(d, col="black")
  plot_layers(y_head=0.00011, y_arrows=c(10, 8), thisSim = thisim)
  
  d <- density(x_all$pos[which(abs(x_all$pca_ALL_PC2_loadings)>PCA_lim )], bw = 1000)
    plot(d, main="B) Locations of outlier PC2 loadings (all SNPs)", bty="l", las=1, ylim=c(0, 6e-05), xlim=c(0,4.5e05), adj=0,
       ylab="", xlab="")
  polygon(d, col="black")
  plot_layers(y_head=10, y_arrows=c(10, 8), thisSim = thisim)
  
  d <- density(x_all$pos[which(abs(x_all$pca_PRUNED_PC1_loadings)>PCA_lim )], bw = 1000)
    plot(d, main="C) Locations of outlier PC1 loadings (trimmed SNPs)", bty="n", las=1, ylim=c(0, 2e-05), xlim=c(0,5e05),adj=0,
       ylab="", xlab="Position (bp)")
  polygon(d, col="black")
  plot_layers(y_head=1.7e-05, y_arrows=c(10, 8), thisSim = thisim)
  
  mtext("Density", side = 2, outer=TRUE, line=0)
dev.off()  

```

### PC from RDA

```{r}
RDApc1 <- x_all$RDAvegan_2.52_ALL_PC1
RDApc2 <- x_all$RDAvegan_2.52_ALL_PC2
RDApc3 <- x_all$RDAvegan_2.52_ALL_PC3

 ### which locations load onto PC all data ####
pdf("figures/WhichLocationsPCs_RDA.pdf", width=9, height=6)  
  par(mar=c(4, 4,1,1), oma=c(0,2,0,0), mfrow=c(3,1))
  d <- density(x_all$pos[which(abs(RDApc1)>
                                 quantile(abs(RDApc1), 0.95, na.rm = TRUE))], bw = 1000)
  plot(d, main="A) Locations of outlier PC1 loadings in RDA (all SNPs)", bty="n", las=1, ylim=c(0, 13e-05), xlim=c(0,5e05),adj=0,
       ylab="", xlab="")
  polygon(d, col="black")
  plot_layers(y_head=0.00011, y_arrows=c(0.00008, 0.00004), thisSim = thisim)
  
  d <- density(x_all$pos[which(abs(RDApc2)>
                                 quantile(abs(RDApc2), 0.95, na.rm = TRUE))], bw = 1000)
    plot(d, main="B) Locations of outlier PC2 loadings in RDA (all SNPs)", bty="n", las=1, ylim=c(0, 3e-05), xlim=c(0,5e05), adj=0,
       ylab="", xlab="")
  polygon(d, col="black")
  plot_layers(y_head=10, y_arrows=c(10, 8), thisSim = thisim)
  
  d <- density(x_all$pos[which(abs(RDApc3)>
                                 quantile(abs(RDApc3), 0.95, na.rm = TRUE))], bw = 1000)
    plot(d, main="C) Locations of outlier PC3 loadings in RDA (all SNPs)", bty="n", las=1, ylim=c(0, 3e-05), xlim=c(0,5e05),adj=0,
       ylab="", xlab="Position (bp)")
  polygon(d, col="black")
  plot_layers(y_head=10, y_arrows=c(10, 8), thisSim = thisim)
  
  mtext("Density", side = 2, outer=TRUE, line=0)
dev.off()  

```

### Visualize genome scans: Manhattan plots
This plot compares a few of the different methods, but is not comprehensive. Depending on the methods to be compared, the code could be copied and used to produce similar plots.

```{r}
thisim = 10945
#thisim = 10916
# 10944

x_old <- x_all

# Some infinite P-values are replaced. This does not affect the interpretation of the results, just makes for nicer plotting
(fix1 <- which(is.infinite(x_all$pcadapt_3.0.4_ALL_log10p)))
x_all$pcadapt_3.0.4_ALL_log10p[fix1] <- NA #max(x_all$pcadapt_3.0.4_ALL_log10p[-fix1], na.rm=TRUE)
max(x_all$pcadapt_3.0.4_ALL_log10p, na.rm=TRUE)

fix2 <- which(is.infinite(x_all$pcadapt_3.0.4_PRUNED_log10p))
str(fix2)

fix3 <- which(is.infinite(x_all$OutFLANK_0.2_ALL_log10p))
str(fix3)
max(x_all$OutFLANK_0.2_ALL_log10p[-fix3], na.rm=TRUE)
x_all$OutFLANK_0.2_ALL_log10p[fix3] <- 16


fix4 <- which(is.infinite(x_all$OutFLANK_0.2_PRUNED_log10p))
str(fix4)
max(x_all$OutFLANK_0.2_ALL_log10p[-fix4], na.rm=TRUE)
x_all$OutFLANK_0.2_PRUNED_log10p[fix4] <- 16

fix5 <- which(is.infinite(x_all$baypass_2.1_PRUNED_XTX))
str(fix5)

hist(x_all$baypass_2.1_ALL_XTX)
hist(x_all$baypass_2.1_PRUNED_XTX)
hist(x_all$baypass_2.1_PRUNED_BF_env)
hist(x_all$baypass_2.1_ALL_BF_env)

fix6 <- which(is.infinite(x_all$LFMM_ridge_0.0_ALL_log10p))
str(fix6)
# Note that the y-axes in the below graphs are specific to this simulation
```


```{r}

makeManhattans <- function(thisim){
  forpdf <- x_all[x_all$simID==thisim,]
  
  ### Manahattan plot comparing selective sweep sims ###
  pdf(paste0("figures/Manhattan_SS_",thisim,".pdf"), width=8, height= 6)
  par(mfrow=c(3,1), mar=c(0.5, 4, 2,0.1), oma=c(3,0,0,0))
   
  (maxp <- max(forpdf$skallel_v1.1.10_H12[forpdf$keep_loci], na.rm=TRUE)) 
  plot(forpdf$pos[forpdf$keep_loci], forpdf$skallel_v1.1.10_H12[forpdf$keep_loci],
        pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
       cex=0.7, ylab= "                  H12", xaxt="n",  type="h", bty="l",
       main="A) H12", adj=0,
       ylim=c(0,maxp*1.7))#, 
       #xlim=c(170000 , 180000))
    plot_layers(y_head=maxp*1.5, y_arrows=c(maxp*1.2, maxp*1.02), thisSim = thisim,)
  
  (maxp <- max(forpdf$skallel_v1.1.10_H2H1[forpdf$keep_loci], na.rm=TRUE))     
  plot(forpdf$pos[forpdf$keep_loci], forpdf$skallel_v1.1.10_H2H1[forpdf$keep_loci],
        pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
       cex=0.7, ylab= "                    H2/H1", xaxt="n",  type="h", bty="l",
       main="B) H2/H1", adj=0,
       ylim=c(0,maxp*1.17))#, 
       #xlim=c(170000 , 180000))
    plot_layers(y_head=12000, y_arrows=c(maxp*1.15, maxp*1.02), thisSim = thisim)
    
  (maxp <- max(forpdf$skallel_v1.1.10_ihs[forpdf$keep_loci], na.rm=TRUE))      
    plot(forpdf$pos[forpdf$keep_loci], abs(forpdf$skallel_v1.1.10_ihs[forpdf$keep_loci]),
        pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
       cex=0.7, ylab= "                  abs(iHS)",  type="h", bty="l",
       main="C) abs(iHS)", adj=0,
       ylim=c(0,maxp*1.17))
    plot_layers(y_head=90, y_arrows=c(maxp*1.15, maxp*1.02), thisSim=thisim)
    # 
    # plot(forpdf$pos[forpdf$keep_loci], forpdf$skallel_v1.1.10_tajD[forpdf$keep_loci],
    #     pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
    #    cex=0.7, ylab= "Tajima's D", xaxt="n",  type="h", bty="l",
    #    main="A) Tajima's D", adj=0,
    #    ylim=c(-1,5))#, 
    #    #xlim=c(170000 , 180000))
    # plot_layers(y_head=12000, y_arrows=c(5, 4), thisSim = thisim)
    # 
    # plot(forpdf$pos, forpdf$skallel_v1.1.10_pi,
    #    pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
    #   cex=0.7, ylab= "pi",  type="h", bty="l",
    #   main="B) pi", adj=0, ylim=c(0, 0.012))
    # plot_layers(y_head=90, y_arrows=c(0.01, 0.008), thisSim=thisim)
    # 
    # plot(forpdf$pos, forpdf$skallel_v1.1.10_thetaW,
    #    pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
    #   cex=0.7, ylab= "Theta W",  type="h", bty="l",
    #   main="B) Theta W", adj=0, ylim=c(0, 0.005))
    # plot_layers(y_head=90, y_arrows=c(0.005, 0.004), thisSim=thisim)
    # 
    # plot(forpdf$pos, abs(forpdf$skallel_v1.1.10_nsl),
    #     pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
    #    cex=0.7, ylab= "nsl",  type="h", bty="l",
    #    main="B) nsl", adj=0, ylim=c(0, 4.5))
    # plot_layers(y_head=90, y_arrows=c(4.5, 3.3), thisSim=thisim)
    
    mtext("Position (bp)", side=1, outer=TRUE, line=2)
  dev.off()

  ### Manahattan plot comparing Differentiation Outliers ###
  pdf(paste0("figures/Manhattan_DO",thisim,".pdf"), width=8, height= 10)
  par(mfrow=c(6,1), mar=c(0.5, 4, 2,0.1), oma=c(3,0,0,0))

    (maxp <- max(forpdf$pcadapt_3.0.4_ALL_log10p, na.rm=TRUE))
    plot(forpdf$pos, forpdf$pcadapt_3.0.4_ALL_log10p,
        ylim= c(0, maxp*1.7), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
       cex=0.5, ylab= "-log10(P) PCAdapt Naive", xaxt="n", type="h", bty="l", main="A) PCAdapt Naive", adj=0)
    plot_layers(y_head=maxp*1.5, y_arrows=c(maxp*1.2, maxp*1.02), thisSim = thisim)
  
     (maxp <- max(forpdf$pcadapt_3.0.4_PRUNED_log10p, na.rm=TRUE))
    plot(forpdf$pos, forpdf$pcadapt_3.0.4_PRUNED_log10p,
       ylim= c(0, maxp*1.19), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
       cex=0.5, ylab= "-log10(P) PCAdapt B.P.", xaxt="n", type="h", bty="l", main="B) PCAdapt Best Practice", adj=0)
    plot_layers(y_head=maxp*100, y_arrows=c(maxp*1.18, maxp*1.05), thisSim=thisim)
  
    (maxp <- max(c(forpdf$OutFLANK_0.2_ALL_log10p, forpdf$OutFLANK_0.2_PRUNED_log10p), na.rm=TRUE))
    plot(forpdf$pos, forpdf$OutFLANK_0.2_ALL_log10p,
       ylim= c(0, maxp*1.19), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
       cex=0.5, ylab= "-log10(P) OutFLANK Naive", xaxt="n", type="h", bty="l", main="C) OutFLANK (Fst) Naive", adj=0)
    plot_layers(y_head=maxp*100, y_arrows=c(maxp*1.18, maxp*1.05), thisSim=thisim)
  
    plot(forpdf$pos, forpdf$OutFLANK_0.2_PRUNED_log10p,
       ylim= c(0, maxp*1.19), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
       cex=0.5, ylab= "-log10(P) OutFLANK B.P.", type="h", xaxt="n", bty="l", main="D) OutFLANK (Fst) Best Practice", adj=0)
    plot_layers(y_head=maxp*100, y_arrows=c(maxp*1.18, maxp*1.05), thisSim=thisim)
    
    (maxp <- max(c(forpdf$baypass_2.1_ALL_XTX, forpdf$baypass_2.1_PRUNED_XTX), na.rm=TRUE))
    plot(forpdf$pos, forpdf$baypass_2.1_ALL_XTX,
       ylim= c(20, maxp*1.19), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
       cex=0.5, ylab= "           XTX Naive", xaxt="n", type="h", bty="l", main="E) BayPass (XTX) Naive", adj=0)
    plot_layers(y_head=150, y_arrows=c(maxp*1.18, maxp*1.05), thisSim=thisim)
  
    plot(forpdf$pos, forpdf$baypass_2.1_PRUNED_XTX,
       ylim= c(20, maxp*1.19), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i",
       cex=0.5, ylab= "              XTX B.P.", type="h", bty="l", main="F) BayPass (XTX) Best Practice", adj=0)
    plot_layers(y_head=0, y_arrows=c(maxp*1.18, maxp*1.05), thisSim=thisim)
    
    mtext("Position (bp)", side=1, outer=TRUE, line=2)
  dev.off()
    
  
  
  ### Manahattan plot comparing Association Tests ###
  

  cor.test(x_all$baypass_2.1_ALL_BF_env, x_all$baypass_2.1_PRUNED_BF_env)
    # Results for environment and phenotype are very similar, just use one
  
  summary(x_all$baypass_2.1_PRUNED_BF_env)
  summary(x_all$baypass_2.1_ALL_BF_env)
  
  pdf(paste0("figures/Manhattan_Assoc",thisim,".pdf"), width=8, height= 12)
  par(mfrow=c(7,1), mar=c(0.5, 4, 2,0.1), oma=c(3,0,0,0))
  
    (maxp <- max(forpdf$LFMM_ridge_0.0_ALL_log10p, na.rm=TRUE))
  plot(forpdf$pos, forpdf$LFMM_ridge_0.0_ALL_log10p,
       ylim= c(0, maxp*1.7), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="A) LFMM ridge (phenotype)", adj=0, ylab="-log10 P (LFMM ridge)", xaxt="n")
  plot_layers(y_head=maxp*1.5, y_arrows=c(maxp*1.2,maxp*1.05), thisSim=thisim)
  
  (maxp <- max(forpdf$LFMM_lasso_0.0_ALL_log10p, na.rm=TRUE))
  plot(forpdf$pos, forpdf$LFMM_lasso_0.0_ALL_log10p,
       ylim= c(0, maxp*1.19), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="B) LFMM lasso (phenotype)", adj=0, ylab="-log10 P (LFMM lasso)", xaxt="n")
  plot_layers(y_head=-100, y_arrows=c(maxp*1.18,maxp*1.05), thisSim=thisim)
  
  (maxp <- max(x_all$Spearmans_ALL_rho, na.rm=TRUE))
  plot(forpdf$pos, abs(forpdf$Spearmans_ALL_rho),
       ylim= c(0, maxp*1.19), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="C) Spearman's rho (environment)", adj=0, ylab="     abs(Spearman's rho)", xaxt="n")
  plot_layers(y_head=-100, y_arrows=c(maxp*1.18,maxp*1.05), thisSim=thisim)
  
  (maxp <- max(forpdf$LEA_1.2.0_ALL_K3_log10p, na.rm=TRUE))
  plot(forpdf$pos, forpdf$LEA_1.2.0_ALL_K3_log10p,
       ylim= c(0, maxp*1.19), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="D) LEA (environment)", adj=0, ylab="        -log10 P (LEA)", xaxt="n")
  plot_layers(y_head=-10, y_arrows=c(maxp*1.18,maxp*1.05), thisSim=thisim)
  
  (maxp <- max(c(forpdf$baypass_2.1_ALL_BF_env, forpdf$baypass_2.1_PRUNED_BF_env), na.rm=TRUE))
  plot(forpdf$pos, forpdf$baypass_2.1_ALL_BF_env,
        pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="E) BayPass Bayes Factor - Naive (environment)", adj=0, ylab="        Bayes Factor Naive", xaxt="n", ylim=c(0, maxp*1.19))
  plot_layers(y_head=-100, y_arrows=c(maxp*1.18,maxp*1.05), thisSim=thisim)
  
  plot(forpdf$pos, forpdf$baypass_2.1_PRUNED_BF_env,
        pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="F) BayPass Bayes Factor - Best Practice (environment)", adj=0, ylab="               Bayes Factor B.P.", xaxt="n", ylim=c(0, maxp*1.19))
  plot_layers(y_head=-100, y_arrows=c(maxp*1.18,maxp*1.05), thisSim=thisim)
  
   (maxp <- max(abs(forpdf$RDAvegan_2.52_ALL_RDA1), na.rm=TRUE))
  plot(forpdf$pos, abs(forpdf$RDAvegan_2.52_ALL_RDA1),
       ylim= c(0, maxp*1.19), pch=19, col=rgb(0,0,0,0.5), xaxs="i", yaxs="i", type="h", bty="l", main="G) RDA (environment)", adj=0, ylab="        loading (RDA)")
  plot_layers(y_head=-10,  y_arrows=c(maxp*1.18,maxp*1.05), thisSim=thisim)
  
  mtext("Position (bp)", side=1, outer=TRUE, line=2)
  
  dev.off()
}# end makeManhattans





# both haplotypes common
makeManhattans(10997) #10997 0.5047847 0.49521531    146
makeManhattans(11019) #11019 0.5015136 0.49848638   9319
makeManhattans(11062) #11062 0.5116162 0.48838384    262
makeManhattans(10906) #10906 0.5061412 0.49385875   3637
makeManhattans(10946) # 10946 0.4091826 0.40918264    210
makeManhattans(10944) #10944 0.5205411 0.47945892   3051

# inversion more common than ancestor
makeManhattans(10913) #10913 0.6919959 0.30800405   3024
makeManhattans(11088) #11088 0.9072948 0.09270517     24

# inversion less common than ancestor
makeManhattans(11107) #11107 0.2568251 0.25682508     15
makeManhattans(10950) #10950 0.2684157 0.26841574    448
```

### AUC-ROC

This section has some code that will need to be edited if results are added.

For programs designed to detect the global sweep, these are evaluated at the sweep only.

For programs designed to detect the loci that differ in allele frequency among populations, or loci that have an association with phenotype or environment, these are evaluated at the QTNs.

There are two performance metrics calculated. The first metric is the Area Under the Curve for the Receiver Operating Characteristics graph (AUC-ROC). The second metric is the Area Under the Curve for the precision-recall graph (AUC-PR), and is probably better because our data contain many neutral loci and only a few selected loci.

This next chunk of code does not need to be edited if adding a new statstic:
```{r}

  # Loop through each statistic
  # Set up a list of predictions
label_list_QTN <- list()
x_all <- x_all %>% mutate(count_QTN = FALSE)
x_all$count_QTN[x_all$prop>=0.01] <- TRUE

label_list_fullSS <- list()
x_all <- x_all %>% mutate(count_fullSS = FALSE)
full_where <- x_all$pos[which(x_all$descrip=="full_sweep")][1]
x_all$count_fullSS[x_all$pos > (full_where-2000) & x_all$pos < (full_where+2000)] <- TRUE
tapply(x_all$count_fullSS,x_all$simID,  sum, na.rm=TRUE)

label_list_partSS <- list()
x_all <- x_all %>% mutate(count_partSS = FALSE)
(part_where <- x_all$pos[which(x_all$descrip=="partial_sweep")][1])
x_all$count_partSS[x_all$pos > (part_where-2000) & x_all$pos < (part_where+2000)] <- TRUE
tapply(x_all$count_partSS,x_all$simID,  sum, na.rm=TRUE)


for (i in 1:length(inver_simID)){
  print(i)
  label_list_QTN[[i]] <- x_all$count_QTN[which(x_all$simID == inver_simID[i])]
  label_list_fullSS[[i]] <- x_all$count_fullSS[which(x_all$simID == inver_simID[i])]
  label_list_partSS[[i]] <- x_all$count_partSS[which(x_all$simID == inver_simID[i])]
}

# loop through columns of data
```


If adding new results, please add the desired statistic here:
```{r}
# To add results to the evaluation, add the names of the columns 
# in the x_all dataframe here
# in the order you would like to see them plotted
# (note that it is easy to remove columns for plotting)
x_all <- x_all %>% mutate(
  RDAvegan_2.52_ALL_RDA1_abs = abs(RDAvegan_2.52_ALL_RDA1), 
  Spearmans_ALL_rho_abs = abs(Spearmans_ALL_rho), 
  skallel_v1.1.10_ihs_abs = abs(skallel_v1.1.10_ihs),
  skallel_v1.1.10_H2H1_mlog10 = -log10(skallel_v1.1.10_H2H1))
  #note that because of directionality of the association the abs() is taken for evaluation

togetcols <- c(
  ##SS methods
      "skallel_v1.1.10_H12", "skallel_v1.1.10_H2H1", "skallel_v1.1.10_H2H1_mlog10", 
      "skallel_v1.1.10_ihs_abs",
  ## DO methods             
      "pcadapt_3.0.4_ALL_log10p","pcadapt_3.0.4_PRUNED_log10p",
      "OutFLANK_0.2_ALL_log10p", "OutFLANK_0.2_PRUNED_log10p",
      "baypass_2.1_ALL_XTX", "baypass_2.1_PRUNED_XTX",
  ## Assoc methods
      "LFMM_ridge_0.0_ALL_log10p", "LFMM_lasso_0.0_ALL_log10p",
      "LEA_1.2.0_ALL_K3_log10p", "Spearmans_ALL_rho_abs",
      "baypass_2.1_ALL_BF_env", "baypass_2.1_PRUNED_BF_env",
      "RDAvegan_2.52_ALL_RDA1_abs"
  )
```

Now your new statistic will be evaluated in this loop:
```{r}
# This code loops through each statistic and each replicate simulation
# and creates a list - basically just putting things into format for analysis
perf_df <- data.frame(method=NULL, perf_fullSS=NULL, perf_QTN=NULL, perf_partSS=NULL)
predict_list <- list()
for (j in 1:length(togetcols)){
  print(paste(j, "of", length(togetcols), togetcols[j], sep=" "))
  for (i in 1:length(inver_simID)){
    if(i%%20==0){print(i)}
  predict_list[[i]] <- as.numeric(unlist(x_all[x_all$simID==inver_simID[i], which(colnames(x_all)==togetcols[j])]))
  }
  #str(predict_list)
  
  # QTN performance
  manypred_QTN = prediction(predict_list, label_list_QTN)
  auc.perf_QTN = performance(manypred_QTN, measure = "auc")
  AUCroc_QTN <- as.numeric(unlist(auc.perf_QTN@y.values))

  # full SS performance
  # note that with only one prediction (sweep site), can't compute AUC
  # done on window around sweep
  manypred_fullSS = prediction(predict_list, label_list_fullSS)
  auc.perf_fullSS = performance(manypred_fullSS, measure = "auc")
  AUCroc_fullSS <- as.numeric(unlist(auc.perf_fullSS@y.values))
  
    # partial SS performance
  # note that with only one prediction (sweep site), can't compute AUC
    # done on window around sweep
  manypred_partSS = prediction(predict_list, label_list_partSS)
  auc.perf_partSS = performance(manypred_partSS, measure = "auc")
  AUCroc_partSS <- as.numeric(unlist(auc.perf_partSS@y.values))
  
  
### AUC- PR calculations for QTN
  getAUCpr_QTN <- function(x){
    sel <- predict_list[[x]][label_list_QTN[[x]]]
    sel <- sel[!is.na(sel)]
    neut <- predict_list[[x]][!label_list_QTN[[x]]]
    neut <- neut[!is.na(neut)]
    AUCpr_QTN_tot <- pr.curve(scores.class0 = sel, 
                          scores.class1 = neut, 
                          rand.compute = TRUE
                          )
    return(data.frame(AUCpr_QTN = AUCpr_QTN_tot$auc.integral,
                      AUCpr_QTN_rand = AUCpr_QTN_tot$rand$auc.integral))
  }
  AUCpr_QTN_final <- matrix(unlist(lapply(1:length(predict_list), getAUCpr_QTN)), nrow=length(predict_list), ncol=2, byrow=TRUE)
  colnames(AUCpr_QTN_final) <- c("AUCpr_QTN", "AUCpr_QTN_rand")

### AUC- PR calculations for SS
  getAUCpr_SS <- function(x){
    selSS_full <- predict_list[[x]][label_list_fullSS[[x]]]
    selSS_part <- predict_list[[x]][label_list_partSS[[x]]]
    selSS_full <- selSS_full[!is.na(selSS_full)]
    selSS_part <- selSS_part[!is.na(selSS_part)]
    neutSS <- predict_list[[x]][!c(label_list_fullSS[[x]], label_list_partSS[[x]])]
    neutSS <- neutSS[!is.na(neutSS)]
    AUCpr_fullSS_tot <- pr.curve(scores.class0 = selSS_full, 
                          scores.class1 = neutSS, 
                          rand.compute = TRUE
                          )
    AUCpr_partSS_tot <- pr.curve(scores.class0 = selSS_part, 
                          scores.class1 = neutSS, 
                          rand.compute = TRUE
                          )
    return(data.frame(AUCpr_fullSS = AUCpr_fullSS_tot$auc.integral,
    AUCpr_fullSS_rand = AUCpr_fullSS_tot$rand$auc.integral,
    AUCpr_partSS = AUCpr_partSS_tot$auc.integral,
    AUCpr_partSS_rand = AUCpr_partSS_tot$rand$auc.integral
    ))
  }
    AUCpr_SS_final <- matrix(unlist(lapply(1:length(predict_list), getAUCpr_SS)), nrow=length(predict_list), ncol=4, byrow=TRUE)
  colnames(AUCpr_SS_final) <- c("AUCpr_fullSS", "AUCpr_fullSS_rand",
                                "AUCpr_partSS", "AUCpr_partSS_rand")

    perf_df <- rbind(perf_df, cbind(data.frame(method=togetcols[j], AUCroc_QTN =AUCroc_QTN , AUCroc_fullSS=AUCroc_fullSS,AUCroc_partSS=AUCroc_partSS, simID = inver_simID), AUCpr_QTN_final, AUCpr_SS_final))
} # end loop through

if (nrow(perf_df) != length(togetcols)*length(inver_simID)){
  print("Error: performance data frame of wrong length"); break;
}
```

Now add the name of how you want your new statistic to be plotted:
```{r}
## If adding new results, update the name of the variable here
## to be the name for plotting
  # ##SS methods
  #     "skallel_v1.1.10_H12", "skallel_v1.1.10_H2H1", "skallel_v1.1.10_H2H1_mlog10", 
  #     "skallel_v1.1.10_ihs",
  # ## DO methods             
  #     "pcadapt_3.0.4_ALL_log10p","pcadapt_3.0.4_PRUNED_log10p",
  #     "OutFLANK_0.2_ALL_log10p", "OutFLANK_0.2_PRUNED_log10p",
  #     "baypass_2.1_ALL_XTX", "baypass_2.1_PRUNED_XTX",
  # ## Assoc methods
  #     "LFMM_ridge_0.0_ALL_log10p", "LFMM_lasso_0.0_ALL_log10p",
  #     "LEA_1.2.0_ALL_K3_log10p", "Spearmans_ALL_rho_abs",
  #     "baypass_2.1_ALL_BF_env", "baypass_2.1_PRUNED_BF_env",
  #     "RDAvegan_2.52_ALL_RDA1"
  
perf_df2 <- perf_df %>%
     mutate(name = recode(method, 
      skallel_v1.1.10_H12 = "H12", 
      skallel_v1.1.10_H2H1 = "H2/H1",
      skallel_v1.1.10_H2H1_mlog10 = "-log(H2/H1)",
      skallel_v1.1.10_ihs_abs = "iHS", 
  ## DO methods             
      pcadapt_3.0.4_ALL_log10p = "PCAdapt Naive",
      pcadapt_3.0.4_PRUNED_log10p = "PCAdapt BP",
      OutFLANK_0.2_ALL_log10p = "OutFLANK Naive", 
      OutFLANK_0.2_PRUNED_log10p = "OutFLANK BP",
      baypass_2.1_ALL_XTX = "XTX Naive", 
      baypass_2.1_PRUNED_XTX = "XTX BP",
  ## Assoc methods
      LFMM_ridge_0.0_ALL_log10p = "LFMM ridge (pheno)", 
      LFMM_lasso_0.0_ALL_log10p = "LFMM lasso (pheno)",
      LEA_1.2.0_ALL_K3_log10p = "LEA (envi)", 
      Spearmans_ALL_rho_abs = "Spearman's rho (envi)",
      baypass_2.1_ALL_BF_env = "BayPass (envi) Naive", 
      baypass_2.1_PRUNED_BF_env = "BayPass (envi) BP",
      RDAvegan_2.52_ALL_RDA1_abs = "RDA (envi) loading"
      ) # end recode
   )
```

And add the color scheme for the new statistic:
```{r}
## Determine color scheme. 
  # If adding new results, you may need to update the color scheme based on the information below:
    # For Only option, blank patterning. 
    # For Naive option, dot patterning.
    # For best practice, hashed patterning.
    ## SS methods - shades of purple
    ## DO methods - shades of orange and red
    ## Assoc methods - shades of blue and green
  # Map color onto perf_df
  # Map shading onto perf_df
plot_df <- data.frame(method=togetcols)
plot_df <- plot_df %>% mutate(color = recode(method,
      skallel_v1.1.10_H12 = "#cfcdf5", # wind chime palette on color-hex.com
      skallel_v1.1.10_H2H1 = "#b4c1f6",
      skallel_v1.1.10_H2H1_mlog10 = "#b4c1f6",
      skallel_v1.1.10_ihs_abs = "#9bc2f7", 
  ## DO methods             
      pcadapt_3.0.4_ALL_log10p = "#ecd292", # amber safety palette on color-hex.com
      pcadapt_3.0.4_PRUNED_log10p = "#ecd292",
      OutFLANK_0.2_ALL_log10p = "#e5a267", 
      OutFLANK_0.2_PRUNED_log10p = "#e5a267",
      baypass_2.1_ALL_XTX = "#d27254", 
      baypass_2.1_PRUNED_XTX = "#d27254",
  ## Assoc methods
      LFMM_ridge_0.0_ALL_log10p = "#2b9ddb", # Dark stormy sea on color-hex.com
      LFMM_lasso_0.0_ALL_log10p = "#394856",
      LEA_1.2.0_ALL_K3_log10p = "#7cfac3", 
      Spearmans_ALL_rho_abs = "#00ab84",
      baypass_2.1_ALL_BF_env = "#9db69f", 
      baypass_2.1_PRUNED_BF_env = "#9db69f",
     RDAvegan_2.52_ALL_RDA1_abs = "#808000"
      )# end recode
) 

head(plot_df)

head(perf_df2)  
tail(perf_df2)


```


Add information about the allele frequency at different regions and the cumulative
density at different regions

```{r}

perf_df2 <- perf_df2 %>% mutate(uniq=paste(method, simID, sep="_"))
head(perf_df2)
if(sum(duplicated(perf_df2$uniq))>0){print("Error in performance data frame"); break}

getQuant_region <- function(method, simid){
    bob <- x_all %>% filter(simID==simid) %>% 
          select(c("prop", method, "simID", "pos", "a_freq_final", "He")) 
    P <- ecdf(unlist(bob[,method]))
    bob$cdf <-  P(unlist(bob[,method]))

    whichbob_LEQTL <- which(bob$prop==max(bob$prop, na.rm=TRUE))
    whichbob_Inversion <- which(bob$pos > 320000 & bob$pos < 330000)
    whichbob_fullSS <- which(bob$pos > (225000-2000) & bob$pos < (225000+2000))
    whichbob_partSS <- which(bob$pos > (275000-2000) & bob$pos < (275000+2000))
    whichbob_lowR <- which(bob$pos > 370000 & bob$pos < 380000)
    whichbob_neut <- which(bob$pos < 100000)
    #whichbob_Rvar <- which(bob$pos > 400001 & bob$pos < 450000)

  data.frame(uniq2=paste(method, simid,sep="_"),
             cdf_LEQTL= bob$cdf[whichbob_LEQTL], #mean(bob$cdf[whichbob_LEQTL], na.rm=TRUE),
             prop_LEQTL=bob$prop[whichbob_LEQTL],
             af_LEQTL= bob$a_freq_final[whichbob_LEQTL],
             cdf_Inversion = mean(bob$cdf[whichbob_Inversion], na.rm=TRUE),
             cdf_fullSS =mean(bob$cdf[whichbob_fullSS], na.rm=TRUE),
             cdf_partSS =mean(bob$cdf[whichbob_partSS], na.rm=TRUE),
             cdf_lowR = mean(bob$cdf[whichbob_lowR], na.rm=TRUE)
             #cdf_Rvar = mean(bob$cdf[whichbob_BS], na.rm=TRUE),
      
             )
  # Take the average signal in the region, and count that for the replicate
}

### Quantiles
perf_df3 <- data.frame()
for (j in 1:nrow(perf_df2)){
  if(j%%50==0){print(c(j, "of", nrow(perf_df2)))}
  doa <- getQuant_region(as.character(perf_df2$method[j]), 
                         as.character(perf_df2$simID[j]))

  perf_df3 <- rbind(perf_df3, cbind(perf_df2[j,], doa))
}


head(perf_df3)
str(perf_df3)

# Add stats on final allele frequency
add_df <- data.frame(simID =  x_all %>% filter(descrip=="full_sweep") %>% select(simID),
      af_fullSS = (x_all %>% filter(descrip=="full_sweep") %>% select(a_freq_final)),
      time_fullSS = (x_all %>% filter(descrip=="full_sweep") %>% select(fixed_since)),
      af_partSS = x_all %>% filter(descrip=="partial_sweep") %>% select( a_freq_final),
      af_inv = x_all %>% filter(descrip=="Inversion") %>% select(a_freq_final),
      af_inv = x_all %>% filter(descrip=="Inversion") %>% select(a_freq_final)
      )
colnames(add_df)
colnames(add_df)[c(2,4,5)] <- c("af_fullSS", "af_partSS", "af_inv")
add_df$simID <- as.factor(add_df$simID)
head(add_df)

table(perf_df3$method, is.na(perf_df3$cdf_Inversion))

df3b <- perf_df3
perf_df3 <- left_join(perf_df3, add_df, by="simID")
str(perf_df3)
if(!(nrow(df3b)==nrow(perf_df3))){print("Error: number of rows not the same")}
```

`perf_df3` now has all the information needed for plotting

## Make AUC-ROC figure
```{r}
# pdf("figures/AUC-ROC.pdf", width=6, height=10)
#   par(mar=c(1, 1, 1,1), mfrow=c(2, 1), oma=c(10, 4,0,0))
#   
#   outstat <- boxplot(perf_df2$AUCroc_fullSS~perf_df2$name, las=2, names=NA,
#           main = "A) Global sweep", col=as.character(plot_df$color),
#           ylim=c(0,1), density=20)
#   abline(h=0.5)
#   rect((1:ngroups)-.4, outstat$stats[2,], (1:ngroups)+.4, outstat$stats[4,],
#        density=dval, angle=aval)
#   
#   outstat2 <- boxplot(perf_df2$AUCroc_QTN ~perf_df2$name, las=2, 
#           main = "B) Causal QTNs",  ylim=c(0,1), col=as.character(plot_df$color))
#   abline(h=0.5)
#   rect((1:ngroups)-.4, outstat2$stats[2,], (1:ngroups)+.4, outstat2$stats[4,],
#        density=dval, angle=aval)
#   
#   mtext("AUC - ROC", side=2, outer=TRUE, line=2, cex=1.5)
# dev.off()
```

## Make AUC-pr boxplot figure
```{r}

boxplot(perf_df2$AUCpr_fullSS_rand~perf_df2$name) # random expectations
boxplot(perf_df2$AUCpr_QTN_rand~perf_df2$name)


str(perf_df2)
perf_df2a <- perf_df2 %>% filter(name != "H2/H1")
dim(perf_df2)
dim(perf_df2a)
perf_df2a$name <- factor(perf_df2a$name)
levels(perf_df2a$name)  

ngroups=nlevels(perf_df2a$name)
levels(perf_df2a$name) 
  dval = c(0,0,0,10,0,10,0,10,0,0,0,0,0,10,0, 0) # If adding new results, may need to edit this line. Naive approach should be hatched (e.g. 10)
  aval=45

if(  length(dval)==ngroups){print("Error wrong number of groups")}
  
pdf("figures/AUC-pr.pdf", width=6, height=10)
  par(mar=c(1, 1, 1,1), mfrow=c(3, 1), oma=c(10, 4,0,0), cex=1.2)
  
  outstat <- boxplot(perf_df2a$AUCpr_fullSS~perf_df2a$name, las=2, names=NA,
          main = "A) Full sweep", col=as.character(plot_df$color),
          ylim=c(0,1), density=20)
  
  rect((1:ngroups)-.4, outstat$stats[2,], (1:ngroups)+.4, outstat$stats[4,],
       density=dval, angle=aval)
  polygon(c(0,100,100,0),c(summary(perf_df2a$AUCpr_fullSS_rand)[1],
                           summary(perf_df2a$AUCpr_fullSS_rand)[1],
                           summary(perf_df2a$AUCpr_fullSS_rand)[6],
                           summary(perf_df2a$AUCpr_fullSS_rand)[6]),
          border=NA, col="grey")
  
  outstat1 <- boxplot(perf_df2a$AUCpr_partSS~perf_df2a$name, las=2, names=NA,
          main = "A) Partial sweep", col=as.character(plot_df$color),
          ylim=c(0,1), density=20)
    polygon(c(0,100,100,0),c(summary(perf_df2a$AUCpr_partSS_rand)[1],
                           summary(perf_df2a$AUCpr_partSS_rand)[1],
                           summary(perf_df2a$AUCpr_partSS_rand)[6],
                           summary(perf_df2a$AUCpr_partSS_rand)[6]),
          border=NA, col="grey")
  
  outstat2 <- boxplot(perf_df2a$AUCpr_QTN~perf_df2a$name, las=2, 
          main = "B) Causal QTNs",  ylim=c(0,1), col=as.character(plot_df$color))
  polygon(c(0,100,100,0),c(summary(perf_df2a$AUCpr_QTN_rand)[1],
                           summary(perf_df2a$AUCpr_QTN_rand)[1],
                           summary(perf_df2a$AUCpr_QTN_rand)[6],
                           summary(perf_df2a$AUCpr_QTN_rand)[6]),
          border=NA, col="grey")
  rect((1:ngroups)-.4, outstat2$stats[2,], (1:ngroups)+.4, outstat2$stats[4,],
       density=dval, angle=aval)
  
  mtext("AUC: Precision-recall", side=2, outer=TRUE, line=2, cex=1.5)
dev.off()
```

### Plot performance stats for sweep area

par(mfrow=c(3,1), mar=c(4,4,1,1), oma=c(0,0,0,0))

## How is H12 affected by allele freq at sweep or inversion? ####
topl <- perf_df3 %>% filter(name=="H12")
plot(topl$af_fullSS, topl$cdf_fullSS, xlim=c(0, 1.0), ylab="quantile of H12",
     xlab="Frequency of sweep", bty="l", pch=19, col=rgb(0.5,0,1,0.3),
     ylim=c(0,1))
points(topl$af_partSS, topl$cdf_partSS, pch=21, col=rgb(0.5,0,1,0.3))
legend(0,0.3,c("Partial", "Full"),pch=c(21,19), col=rgb(0.5,0,1,0.3), 
       horiz = TRUE, box.col ="lightgrey", cex=0.8)

plot(topl$fixed_since[topl$fixed_since>1], topl$cdf_fullSS[topl$fixed_since>1],  ylab="quantile of H12",
     xlab="Generations since fixation", bty="l", pch=19, col=rgb(0.5,0,1,0.3),
     ylim=c(0,1))

topl$af_invMAF[topl$af_inv>0.5] <- 1- topl$af_inv[topl$af_inv>0.5]

plot(topl$af_invMAF, topl$cdf_Inversion, xlim=c(0, 0.5), ylab="quantile of H12",
     xlab="Minor haplotype freq.\n at inversion", bty="l", pch=19, col=rgb(0.5,0,1,0.3),
     ylim=c(0,1))
#abline(lm(topl$cdf_Inversion~topl$af_invMAF))
```

```{r plot af vs quantile H2/H1}
par(mfrow=c(3,1), mar=c(4,4,1,1), oma=c(0,0,0,0))

unique(perf_df3$name)
## How is H12 affected by allele freq at sweep or inversion? ####
topl <- perf_df3 %>% filter(name=="H2/H1")
plot(topl$af_fullSS, topl$cdf_fullSS, xlim=c(0, 1.0), ylab="quantile of H12",
     xlab="Frequency of sweep", bty="l", pch=19, col=rgb(0.5,0,1,0.3),
     ylim=c(0,1))
points(topl$af_partSS, topl$cdf_partSS, pch=21, col=rgb(0.5,0,1,0.3))
legend(0,0.3,c("Partial", "Full"),pch=c(21,19), col=rgb(0.5,0,1,0.3), 
       horiz = TRUE, box.col ="lightgrey", cex=0.8)

plot(topl$fixedsince_fullSS[topl$fixedsince_fullSS>1], topl$cdf_fullSS[topl$fixedsince_fullSS>1],  ylab="quantile of H12",
     xlab="Generations since fixation", bty="l", pch=19, col=rgb(0.5,0,1,0.3),
     ylim=c(0,1))

topl$af_invMAF[topl$af_inv>0.5] <- 1- topl$af_inv[topl$af_inv>0.5]

plot(topl$af_invMAF, topl$cdf_Inversion, xlim=c(0, 0.5), ylab="quantile of H12",
     xlab="Minor haplotype freq.\n at inversion", bty="l", pch=19, col=rgb(0.5,0,1,0.3),
     ylim=c(0,1))
#abline(lm(topl$cdf_Inversion~topl$af_invMAF))
```








## Make AUC-pr curve for a sim
This is way too much code for this plot, but it works
```{r}

THIS IS HARD CODED NEED TO EDIT

MakeAUCPRcurve <- function(thisim, let){  
  prdf <- x_all %>% filter(simID==thisim)
  labels <- label_list_QTN[[which(inver_simID==thisim)]]
  
  todo <- c(4,6,8) #compare pcadapt, outflank, and baypass
    togetcols[todo]
  
  aucz = c()  
  for (i in todo){
    print(togetcols[i])
    stat <- unlist(prdf[,togetcols[i]])
    neut <- stat[!labels]
    neut <- neut[!is.na(neut)]
    sel <- stat[which(labels)]
    sel <- sel[!is.na(sel)]
    wpr <- pr.curve(scores.class0 = sel, scores.class1 = neut, curve = TRUE)
    #plot(wpr)
    print("top signals for neutral loci")
    print(head(as.numeric(sort(neut, decreasing = TRUE))))
    print("top hits for causal loci")
    print(head(as.numeric(sort(sel, decreasing = TRUE))))
    aucz = c(aucz, wpr$auc.integral) 
    if(i==4){
      plot(wpr$curve[,1], wpr$curve[,2], col="purple", ylim=c(0,1), type="l",
           bty="l", xlab="Recall\n(proportion of causal loci discovered)", ylab="Precision\n(proportion of positive hits\nthat are causal loci)", lwd=2, main=paste(let,") Simulation ", thisim, sep=""))
    }
    if(i==6){
      points(wpr$curve[,1], wpr$curve[,2], col="orange", ylim=c(0,1), type="l", lty=2, lwd=2)
    }
    if(i==8){
      points(wpr$curve[,1], wpr$curve[,2], col="lightblue", ylim=c(0,1), type="l", lty=3, lwd=2.5)
    }
  }# end loop
    aucz=round(aucz,2)
    legend(0.4,1, c(paste("PCAdapt AUC = ",aucz[1]), 
                    paste("OutFLANK AUC = ", aucz[2]),
                    paste("XTX AUC = ", aucz[3])),
           lwd=c(2,2,2.5), lty=c(1,2,3), col=c("purple", "orange", "lightblue"), bty="n")
}

pdf("figures/AUC-pr-curves.pdf", width=4, height=8)
  par(mar=c(4,6,4,1), mfrow=c(3,1), oma=c(0,0,0,0))
MakeAUCPRcurve(10944, "A") # pcadapt and baypass
MakeAUCPRcurve(10946, "B") # outflank and pcadapt
MakeAUCPRcurve(10947, "C") # outflank and baypass
dev.off()
```

## Make figures showing percentiles of signals in different regions

```{r plot quantile figures}   
pdf("figures/Quantiles_lowR.pdf", width=6, height=10)
  par(mar=c(1, 1, 2,1), mfrow=c(2, 1), oma=c(10, 4,0,0))
  
  outstat <- boxplot(perf_df3$cdf_Inversion*100~perf_df3$name, las=2, names=NA,
          main = "A) Inversion (LG 7)", col=as.character(plot_df$color),
          ylim=c(0,100), density=20)
  abline(h=50)
  rect((1:ngroups)-.4, outstat$stats[2,], (1:ngroups)+.4, outstat$stats[4,],
       density=dval, angle=aval)
  
  outstat2 <- boxplot(perf_df3$cdf_lowR*100~perf_df3$name, las=2, 
          main = "B) Low recombination (r = 1e-08, LG 8)",  ylim=c(0,100), col=as.character(plot_df$color))
  abline(h=50)
  rect((1:ngroups)-.4, outstat2$stats[2,], (1:ngroups)+.4, outstat2$stats[4,],
       density=dval, angle=aval)
  
  
  mtext("Mean percentile", side=2, outer=TRUE, line=2, cex=1.5)
dev.off()




pdf("figures/Quantiles_other.pdf", width=6, height=10)
  par(mar=c(1, 1, 2,1), mfrow=c(3, 1), oma=c(10, 4,0,0))
  
  outstat <- boxplot(perf_df3$cdf_fullSS*100~perf_df3$name, las=2, names=NA,
          main = "A) Global sweep (LG 4)", col=as.character(plot_df$color),
          ylim=c(0,100), density=20, adj=0)
  abline(h=50)
  rect((1:ngroups)-.4, outstat$stats[2,], (1:ngroups)+.4, outstat$stats[4,],
       density=dval, angle=aval)
  
    outstat1 <- boxplot(perf_df3$cdf_partSS*100~perf_df3$name, las=2, names=NA,
          main = "A) Partial sweep (LG 4)", col=as.character(plot_df$color),
          ylim=c(0,100), density=20, adj=0)
  abline(h=50)
  rect((1:ngroups)-.4, outstat1$stats[2,], (1:ngroups)+.4, outstat1$stats[4,],
       density=dval, angle=aval)
  
  outstat2 <- boxplot(perf_df3$cdf_LEQTL*100~perf_df3$name, las=2, 
          main = "B) Largest effect QTN (LG 2 or 3)",  ylim=c(0,100), col=as.character(plot_df$color), adj=0)
  abline(h=50)
  rect((1:ngroups)-.4, outstat2$stats[2,], (1:ngroups)+.4, outstat2$stats[4,],
       density=dval, angle=aval)
  
  mtext("Mean percentile", side=2, outer=TRUE, line=2, cex=1.5)
dev.off()
```

```{r}
plot(topl$a_freq_final.3,  topl$cdf_LEQTL)
```

```{r plot af vs quantile H12}


## Some other checks and data analysis

```{r}
# low he sites
par(mar=c(4,4,1,1), mfrow=c(1,1))
hist(x_all$pos[x_all$OutFLANK_0.2_He<0.05], breaks=seq(0,500000, by=10000))
plot_layers()

# Quantify outliers in recombination variation region based on P-value
-log10(0.05/7000)
# Bonferroni significant if -log10(P) > 5
# Or BF > 2
x_rv <- (x_all %>% filter(pos  > 400001 & pos < 450000) )
mean(table(x_rv$simID))
  # about 700 sites in this region

togetcols

# Calculate proportion of sites that are outliers in R-var region
Rvar_Pval <- function(method){
  yo1 <- x_rv %>% select(method, simID)
  tapply(unlist(yo1[,method]), yo1$simID, function(x){sum(x>5, na.rm=TRUE)/sum(!is.na(x))})
}

mean(Rvar_Pval("pcadapt_3.0.4_ALL_log10p"))
mean(Rvar_Pval("pcadapt_3.0.4_PRUNED_log10p"))


Rvar_BF <- function(method){
  yo1 <- x_rv %>% select(method, simID)
  tapply(unlist(yo1[,method]), yo1$simID, function(x){sum(x>2, na.rm=TRUE)/sum(!is.na(x))})
}
mean(Rvar_BF("baypass_2.1_ALL_BF_env"))
mean(Rvar_BF("baypass_2.1_PRUNED_BF_env"))
0.003*700

Rvar_quant <- function(method){
  yo1 <- x_rv %>% select(method, simID)
  q <- x_all %>% select(method) %>% unlist %>% quantile(0.95, na.rm=TRUE)
  tapply(unlist(yo1[,method]), yo1$simID, function(x){sum(x>q, na.rm=TRUE)/sum(!is.na(x))})
}
summary(Rvar_quant("Hscan_v1.3_H12"))
summary(Rvar_quant("rehh_2.0.2_ALL_log10p"))
summary(Rvar_Pval("rehh_2.0.2_ALL_log10p"))


# Quantify BF for inversion region
x_inv <- (x_all %>% filter(pos  > 320000 & pos < 330000) )
Inv_BF <- function(method){
  yo1 <- x_inv %>% select(method, simID)
  tapply(unlist(yo1[,method]), yo1$simID, mean)
}
mean(Inv_BF("baypass_2.1_ALL_BF_env"))
mean(Inv_BF("baypass_2.1_PRUNED_BF_env"))
quantile(unlist(x_all[,"baypass_2.1_ALL_BF_env"]), c(0.5,0.6), na.rm=TRUE)

# 
```

```{r}
sessionInfo()
```